{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56802f23",
   "metadata": {},
   "source": [
    "<Center>\n",
    "    <h1 style=\"font-family: Roboto slab\">\n",
    "        <p>\n",
    "        <font color=\"white\">\n",
    "            Sentiment Mining for Amazon Devices: \n",
    "            <br>\n",
    "            Applying Natural Language Processing with Machine Learning and Deep Learning Techniques\n",
    "        </font>\n",
    "    </h1>\n",
    "    <h3 style=\"font-family: Roboto slab\">\n",
    "        <font color=\"yellow\">\n",
    "            Notebook 4/5: Model Development\n",
    "        </font>\n",
    "    </h3>\n",
    "</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59c21d",
   "metadata": {},
   "source": [
    "# I. Introduction & Context\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642afdd4",
   "metadata": {},
   "source": [
    "### <font color = \"yellow\" >Objective:</font>\n",
    "This project aims to build a sentiment analysis tool to classify customer reviews of Amazon devices as positive, negative, or neutral. <br>\n",
    "\n",
    "The project involves preprocessing review text, extracting key features, and implementing both traditional machine learning models (Logistic Regression, Naive Bayes, Support Vector Machines, ...) and deep learning models (LSTM-based RNNs). After training and evaluating these models, the project will compare their performance to select the most effective one for deployment in the sentiment analysis tool. This approach ensures that the tool utilizes the best-performing model to deliver accurate sentiment classification, ultimately supporting better business decisions and product improvements.\n",
    "\n",
    "### <font color = \"yellow\">Application Overview:</font>\n",
    "This application approach is divided into 5 core steps:\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 1:</u>  Data Collection\n",
    "        <ul>\n",
    "            <li> <b>Description:</b> Gather Amazon devices reviews from Amazon's website using web scraping techniques: Selenium, BeautifulSoup, scrape review data to capture review_id, Reviewer, Rating, Date, Review_title, Review_content, Product_id & Product_link</li>\n",
    "            <li> <b> Output: </b> Raw dataset of Amazon device reviews, including review text, star ratings, and other relevant metadata.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 2:</u> Data Pre-Processing\n",
    "        <ul>\n",
    "            <li><b> Description: </b> Clean and prepare the review text for exploratory analysis. Identify and resolve missing values or inconsistencies in the dataset. Convert text to lowercase, remove special characters, stop words, punctuations; apply tokenization and lemmatization.\n",
    "            </li>\n",
    "            <li> <b> Output: </b> Cleaned dataset for EDA and model development.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 3:</u> Exploratory Data Analysis\n",
    "        <ul>\n",
    "            <li>Data Distribution: Analyze review counts across sentiment classes. </li>\n",
    "            <li>Text Analysis: Review text length, word count, and common words.</li>\n",
    "            <li>Sentiment Visualization: Visualize trends in positive, neutral, and negative reviews.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 4:</u > Model Development\n",
    "         <ul>\n",
    "            <li>Developing 5 machine learning and LSTM deep learning models.</li>\n",
    "            <li>Evaluating models performance.</li>\n",
    "            <li>Selecting the best model for final hyperparameter tuning</li>\n",
    "            <li>Validating final model's predictions on 10 new real reviews</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<ul>\n",
    "    <li>\n",
    "        <u>Step 5:</u> Model Deployment\n",
    "        <ul>\n",
    "            <li>Deploy the sentiment analysis model via a Flask API and create a website for users to input reviews and view predicted sentiments in real-time.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ba2cc",
   "metadata": {},
   "source": [
    "# II. Load Pre-Processed Data\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1b3e3",
   "metadata": {},
   "source": [
    "## <font color = \"red\">1.  Libaries Import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eac0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vytran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/vytran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vytran/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/vytran/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/vytran/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Word Frequencies\n",
    "from collections import Counter\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"LightGBM\")\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "import joblib\n",
    "\n",
    "# Deep Learning Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, fbeta_score, make_scorer, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# For final model prediction\n",
    "import html\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cbda5",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.  Dataset import</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "67abf442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "process_reviews = pd.read_excel('../data/cleaned_amazon_reviews.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4d5b27e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15791, 10)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check columns and rows\n",
    "process_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "db08fbaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_id</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Product_id</th>\n",
       "      <th>Review_len</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Full_review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R192QJ45JRSLTC</td>\n",
       "      <td>5</td>\n",
       "      <td>B08JHCVHTY</td>\n",
       "      <td>2558</td>\n",
       "      <td>356</td>\n",
       "      <td>not think need wish blink subscription basic p...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RLJN0G2I0CRNC</td>\n",
       "      <td>5</td>\n",
       "      <td>B08JHCVHTY</td>\n",
       "      <td>190</td>\n",
       "      <td>37</td>\n",
       "      <td>worth every penny blink camera house year peac...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R19D78F9YK0DVA</td>\n",
       "      <td>5</td>\n",
       "      <td>B08JHCVHTY</td>\n",
       "      <td>638</td>\n",
       "      <td>97</td>\n",
       "      <td>quite satisfied use blink subscription plus pl...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R2W7QUYHDCN6CB</td>\n",
       "      <td>4</td>\n",
       "      <td>B08JHCVHTY</td>\n",
       "      <td>996</td>\n",
       "      <td>189</td>\n",
       "      <td>nice add security really like camera give u st...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RM9R0N4N310DC</td>\n",
       "      <td>5</td>\n",
       "      <td>B08JHCVHTY</td>\n",
       "      <td>766</td>\n",
       "      <td>114</td>\n",
       "      <td>great item blink subscription plus plan fantas...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Review_id  Rating  Product_id  Review_len  Word_count  \\\n",
       "0  R192QJ45JRSLTC       5  B08JHCVHTY        2558         356   \n",
       "1   RLJN0G2I0CRNC       5  B08JHCVHTY         190          37   \n",
       "2  R19D78F9YK0DVA       5  B08JHCVHTY         638          97   \n",
       "3  R2W7QUYHDCN6CB       4  B08JHCVHTY         996         189   \n",
       "4   RM9R0N4N310DC       5  B08JHCVHTY         766         114   \n",
       "\n",
       "                                         Full_review Sentiment  Day  Month  \\\n",
       "0  not think need wish blink subscription basic p...  Positive   13      7   \n",
       "1  worth every penny blink camera house year peac...  Positive   10     12   \n",
       "2  quite satisfied use blink subscription plus pl...  Positive   10     11   \n",
       "3  nice add security really like camera give u st...  Positive   26      9   \n",
       "4  great item blink subscription plus plan fantas...  Positive   21     10   \n",
       "\n",
       "   Year  \n",
       "0  2024  \n",
       "1  2024  \n",
       "2  2024  \n",
       "3  2024  \n",
       "4  2024  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.reset_option('display.max_colwidth')\n",
    "process_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f4698",
   "metadata": {},
   "source": [
    "# III. Machine Learning Model Development\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cd2ac",
   "metadata": {},
   "source": [
    "## <font color=\"red\">1.  Data Preparation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ebb0c",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.1. Feature Extraction and TF-IDF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f8f8e",
   "metadata": {},
   "source": [
    "Feature extraction is the process of converting raw data into meaningful numerical features that machine learning models can use. \n",
    "\n",
    "In this project, TF-IDF (Term Frequency-Inverse Document Frequency) is used as the feature extraction technique to transform text reviews into numerical features. This tranformation helps machine learning models learn the importance of specific words in a document relative to the entire corpus by assigning a weight to each word. This ensures that words commonly used across all reviews (e.g., \"the,\" \"is\") are weighted lower, while words specific to a review (e.g., \"amazing,\" \"poor\") are given higher weights.\n",
    "\n",
    "- **TF**: Counts the frequency of a word in a review.\n",
    "- **IDF**: Reduces the weight of common words across multiple reviews.\n",
    "\n",
    "Output: A sparse matrix of numerical features, where each column represents a word, and each row corresponds to a review.\n",
    "\n",
    "Key considerations in this project:\n",
    "\n",
    "- ngram_range=(1,2): Captures both unigrams (single words) and bigrams (two consecutive words) in the feature set.\n",
    "- max_features=5000: Limits the number of features (terms or n-grams) to the top 5,000 based on their relevance in the dataset.\n",
    "- min_df=1: Ensures terms appear in at least 1 document to be included in the feature matrix (effectively includes all terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c60aa06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = process_reviews['Full_review']  # Feature: text reviews\n",
    "y = process_reviews['Sentiment']    # Target: sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00dacd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (15791, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text data into TF-IDF features\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, \n",
    "    ngram_range=(1,2), \n",
    "    min_df=1                # Includes terms that appear in at least 1 document.\n",
    "    )\n",
    "\n",
    "# Generate the TF-IDF feature matrix\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"TF-IDF Matrix Shape:\", X_tfidf.shape)\n",
    "\n",
    "# Save the trained vectorizer to a file for later use\n",
    "joblib.dump(vectorizer, '../models/tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fcb9c",
   "metadata": {},
   "source": [
    "The TfidfVectorizer transforms the text data into a feature matrix where each row represents a review, and each column corresponds to a specific bigram (two-word sequence). The values represent the importance (weight) of the bigram in the review relative to the entire dataset\n",
    "\n",
    "The shape of the TF-IDF matrix confirms the transformation:\n",
    "- Rows (15697): Correspond to the number of reviews in the dataset.\n",
    "- Columns (5000): Represent the selected bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f64133",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.2. Train - Test Split</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4701a7bf",
   "metadata": {},
   "source": [
    "The dataset is split into training and test sets with 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11adda66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59464a",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.3. Imbalance handling with SMOTE</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d674243",
   "metadata": {},
   "source": [
    "Synthetic Minority Oversampling Technique (SMOTE) is a method used to address class imbalance in datasets. It works by generating synthetic samples for minority classes through interpolation between existing data points, creating a more balanced dataset for training machine learning models. SMOTE is particularly effective when the dataset has significantly fewer samples in one or more classes, which can lead to biased model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5518cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before train-test split:\n",
      "Sentiment\n",
      "Positive    8327\n",
      "Neutral     4020\n",
      "Negative    3444\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in training set before SMOTE:\n",
      "Sentiment\n",
      "Positive    6629\n",
      "Neutral     3236\n",
      "Negative    2767\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution before imbalance handling\n",
    "print(\"Class distribution before train-test split:\")\n",
    "print(y.value_counts())  # Use Counter to display class counts\n",
    "\n",
    "# Check class distribution in the training set\n",
    "print(\"\\nClass distribution in training set before SMOTE:\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7b6576e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in training set after SMOTE:\n",
      "Sentiment\n",
      "Positive    6629\n",
      "Negative    6629\n",
      "Neutral     6629\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after applying SMOTE\n",
    "print(\"\\nClass distribution in training set after SMOTE:\")\n",
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a223f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 12632\n",
      "Resampled training set size: 19887\n",
      "Number of synthetic samples added: 7255\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the original and resampled datasets\n",
    "print(\"Original training set size:\", y_train.shape[0])\n",
    "print(\"Resampled training set size:\", y_train_resampled.shape[0])\n",
    "print(\"Number of synthetic samples added:\", y_train_resampled.shape[0] - y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1187f86",
   "metadata": {},
   "source": [
    "After applying SMOTE, the class distribution in the training set is perfectly balanced, with an equal number of samples (6629) for each sentiment category: Positive, Negative, and Neutral. This ensures fair representation of all classes during training, reducing the risk of model bias toward the majority class and improving its ability to classify minority classes accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47482a3",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.4. Evaluation Metric: F1-Score (Weighted Average) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a636db8",
   "metadata": {},
   "source": [
    "The **F1-score** balances precision and recall, making it effective for addressing both false positives and false negatives in sentiment analysis.  \n",
    "\n",
    "The **weighted average** accounts for class imbalance, ensuring a fair evaluation of the model's performance across all sentiment categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5d3c09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the cross-validation strategy used to split the dataset into training and validation sets for model evaluation\n",
    "cross_validation = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)\n",
    "\n",
    "# Defines Weighted F1-score as the evaluation metric for hyperparameter search\n",
    "def custom_f1_scorer(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom F1 scorer to handle multiclass classification.\n",
    "    Uses 'weighted' averaging to account for class imbalance.\n",
    "    \"\"\"\n",
    "    return f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Wrap the custom function with make_scorer\n",
    "f1_weighted_scorer = make_scorer(custom_f1_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d029db",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.  Model Development</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf37448",
   "metadata": {},
   "source": [
    "**Five machine learning models will be trained using the resampled training dataset:**\n",
    "\n",
    "- Logistic Regression: A linear model for classification that predicts probabilities for binary or multiclass outcomes.\n",
    "- Naive Bayes: A probabilistic model suitable for text data and categorical features, based on Bayes' theorem.\n",
    "- LinearSVC: A linear Support Vector Classifier optimized for large, high-dimensional datasets.\n",
    "- Random Forest: An ensemble learning method based on decision trees, known for robustness and reduced overfitting.\n",
    "- LightGBM: A gradient boosting framework optimized for speed and efficiency with large datasets.\n",
    "\n",
    "**Work flow:**\n",
    "- Defines a parameter grid for hyperparameter tuning.\n",
    "- Uses GridSearchCV for cross-validation and hyperparameter optimization.\n",
    "- Extracts the best parameters and trains the models.\n",
    "- Evaluates the model on the test set.\n",
    "- Saves the trained model as a .pkl file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338266a",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.1. Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f2a03111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "Best Parameters for Logistic Regression: {'C': 100, 'solver': 'liblinear'}\n",
      "Best Cross-Validation Accuracy: 0.8418\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_log = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.0, 10, 100],       # The 'C' parameter controls the strength of regularization in Logistic Regression.\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\", \"saga\"]     # The 'solver' parameter specifies the optimization algorithm to use for training Logistic Regression.\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression Model\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_log = GridSearchCV(\n",
    "    estimator=log_model,\n",
    "    param_grid=param_grid_log,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer, # # Weighted F1-score as the evaluation metric for hyperparameter search\n",
    "    verbose=True,               # Displays progress and status of the grid search.\n",
    "    n_jobs=1                    # Parallelizes the computation to speed up the search.\n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_log.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_log = grid_search_log.best_params_\n",
    "print(f\"Best Parameters for Logistic Regression: {best_params_log}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_log.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_log = grid_search_log.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_log.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_log, '../models/logistic_regression_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d6888670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>481</td>\n",
       "      <td>105</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>118</td>\n",
       "      <td>529</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>131</td>\n",
       "      <td>219</td>\n",
       "      <td>1348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              481      105        91\n",
       "Neutral               118      529       137\n",
       "Positive              131      219      1348"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_log = pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ab7eceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_log = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_log = report_log[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_log = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_log = round(weighted_avg_log[\"recall\"], 2)\n",
    "precision_log = round(weighted_avg_log[\"precision\"], 2)\n",
    "f1_score_log = round(weighted_avg_log[\"f1-score\"], 2)\n",
    "f3_score_log = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "766a1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.66      0.71      0.68       677\n",
      "     Neutral       0.62      0.67      0.65       784\n",
      "    Positive       0.86      0.79      0.82      1698\n",
      "\n",
      "    accuracy                           0.75      3159\n",
      "   macro avg       0.71      0.73      0.72      3159\n",
      "weighted avg       0.75      0.75      0.75      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5187e3d",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.2.  Random Forest</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d4dac27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n",
      "Best Parameters for Random Forest: {'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 150}\n",
      "Best Cross-Validation Accuracy: 0.7627\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [75, 100, 125, 150, 175],  # Number of trees in the forest\n",
    "    \"max_depth\": [7, 12],  # Maximum depth of the tree\n",
    "    \"min_samples_split\": [2, 3],  # Minimum samples required to split a node\n",
    "    \"criterion\": [\"gini\", \"entropy\"],  # Splitting criteria\n",
    "    \"min_samples_leaf\": [1, 3]\n",
    "}\n",
    "\n",
    "# Initialize Model\n",
    "rf_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer,     # Weighted F1-score as the evaluation metric for hyperparameter search\n",
    "    verbose=True,                   # Displays progress and status of the grid search.\n",
    "    n_jobs=-1                       # Parallelizes the computation to speed up the search.\n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(f\"Best Parameters for Random Forest: {best_params_rf}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_rf.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_rf.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_rf, '../models/random_forest_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "21cacdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>414</td>\n",
       "      <td>158</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>117</td>\n",
       "      <td>546</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>110</td>\n",
       "      <td>226</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              414      158       105\n",
       "Neutral               117      546       121\n",
       "Positive              110      226      1362"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_rf= pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aefb6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_rf = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_rf = report_rf[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_rf = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_rf = round(weighted_avg_rf[\"recall\"], 2)\n",
    "precision_rf = round(weighted_avg_rf[\"precision\"], 2)\n",
    "f1_score_rf = round(weighted_avg_rf[\"f1-score\"], 2)\n",
    "f3_score_rf = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3bf4ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.74\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.61      0.63       677\n",
      "     Neutral       0.59      0.70      0.64       784\n",
      "    Positive       0.86      0.80      0.83      1698\n",
      "\n",
      "    accuracy                           0.74      3159\n",
      "   macro avg       0.70      0.70      0.70      3159\n",
      "weighted avg       0.75      0.74      0.74      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86670128",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.3.  Naive Bayes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8cc95d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Parameters for Naive Bayes: {'alpha': 0.1}\n",
      "Best Cross-Validation Accuracy: 0.7888\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_nb = {\n",
    "    # The 'alpha' parameter is used for smoothing in Naive Bayes\n",
    "    \"alpha\": [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "# Initialize Model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_nb = GridSearchCV(\n",
    "    estimator=nb_model,\n",
    "    param_grid=param_grid_nb,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer,      # Weighted F1-score as the evaluation metric for hyperparameter search   \n",
    "    verbose=1,                   \n",
    "    n_jobs=-1                   \n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_nb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_nb = grid_search_nb.best_params_\n",
    "print(f\"Best Parameters for Naive Bayes: {best_params_nb}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_nb.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_nb = grid_search_nb.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_nb.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_nb, '../models/naive_bayes_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ccc24661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>485</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>109</td>\n",
       "      <td>558</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>127</td>\n",
       "      <td>170</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              485      100        92\n",
       "Neutral               109      558       117\n",
       "Positive              127      170      1401"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_nb= pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3e97723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_nb = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_nb = report_nb[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_nb = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_nb = round(weighted_avg_nb[\"recall\"], 2)\n",
    "precision_nb = round(weighted_avg_nb[\"precision\"], 2)\n",
    "f1_score_nb = round(weighted_avg_nb[\"f1-score\"], 2)\n",
    "f3_score_nb = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "19539690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.77\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.72      0.69       677\n",
      "     Neutral       0.67      0.71      0.69       784\n",
      "    Positive       0.87      0.83      0.85      1698\n",
      "\n",
      "    accuracy                           0.77      3159\n",
      "   macro avg       0.74      0.75      0.74      3159\n",
      "weighted avg       0.78      0.77      0.78      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade4fd0",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.4. LinearSVC (Linear Support Vector Machine)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b3ca5996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best Parameters for LinearSVC: {'C': 10, 'class_weight': 'balanced', 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2', 'tol': 0.0001}\n",
      "Best Cross-Validation Accuracy: 0.8376\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_linear_svc = {\n",
    "    \"C\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],  # Fine-tuned range for regularization strength\n",
    "    \"penalty\": [\"l2\"],                                  # Regularization type\n",
    "    \"dual\": [False],                                    # Suitable for small datasets\n",
    "    \"loss\": [\"squared_hinge\"],                          # Compare different loss functions\n",
    "    \"tol\": [1e-3, 1e-4],                                # Tolerance for stopping criteria\n",
    "    \"class_weight\": [None, \"balanced\"],                 # Handle imbalanced classes\n",
    "}\n",
    "\n",
    "# Initialize Linear SVM Model\n",
    "linear_svc_model = LinearSVC(random_state=42, max_iter=10000)\n",
    "\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_linear_svc = GridSearchCV(\n",
    "    estimator=linear_svc_model,\n",
    "    param_grid=param_grid_linear_svc,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer,        # Weighted F1-score as the evaluation metric for hyperparameter search  \n",
    "    verbose=1,                   \n",
    "    n_jobs=-1                    \n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_linear_svc.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_linear_svc = grid_search_linear_svc.best_params_\n",
    "print(f\"Best Parameters for LinearSVC: {best_params_linear_svc}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_linear_svc.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_linear_svc = grid_search_linear_svc.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_linear_svc.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_linear_svc, '../models/linearsvc_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9e49ca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>475</td>\n",
       "      <td>109</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>119</td>\n",
       "      <td>520</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>133</td>\n",
       "      <td>227</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              475      109        93\n",
       "Neutral               119      520       145\n",
       "Positive              133      227      1338"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_linear_svc= pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0ba5b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_linear_svc = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_linear_svc = report_linear_svc[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_linear_svc = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_linear_svc = round(weighted_avg_linear_svc[\"recall\"], 2)\n",
    "precision_linear_svc = round(weighted_avg_linear_svc[\"precision\"], 2)\n",
    "f1_score_linear_svc = round(weighted_avg_linear_svc[\"f1-score\"], 2)\n",
    "f3_score_linear_svc = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f1946329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.74\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.70      0.68       677\n",
      "     Neutral       0.61      0.66      0.63       784\n",
      "    Positive       0.85      0.79      0.82      1698\n",
      "\n",
      "    accuracy                           0.74      3159\n",
      "   macro avg       0.70      0.72      0.71      3159\n",
      "weighted avg       0.75      0.74      0.74      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc544d",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.5. LightGBM (Light Gradient Boosting Machine)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6056d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom evaluation metric for LightGBM\n",
    "def custom_f1_metric_lightgbm(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric for LightGBM to compute the weighted F1-score during training.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth labels\n",
    "    - y_pred: Predicted probabilities for each class\n",
    "\n",
    "    Returns:\n",
    "    - Metric name (\"f1_score\"), computed F1-score, and a boolean indicating that higher is better\n",
    "    \"\"\"\n",
    "    y_pred_classes = y_pred.argmax(axis=1)  # Convert probabilities to predicted class labels\n",
    "    f1 = f1_score(y_true, y_pred_classes, average=\"weighted\")\n",
    "    return \"f1_score\", f1, True  # Return metric name, value, and \"higher is better\" indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "43e923da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03466\tvalid_0's f1_score: 0.701326\n",
      "[10]\tvalid_0's multi_logloss: 1.03478\tvalid_0's f1_score: 0.707675\n",
      "[10]\tvalid_0's multi_logloss: 1.03585\tvalid_0's f1_score: 0.692986\n",
      "[10]\tvalid_0's multi_logloss: 1.03466\tvalid_0's f1_score: 0.701326\n",
      "[10]\tvalid_0's multi_logloss: 1.03585\tvalid_0's f1_score: 0.692986\n",
      "[10]\tvalid_0's multi_logloss: 1.02989\tvalid_0's f1_score: 0.722368\n",
      "[10]\tvalid_0's multi_logloss: 1.02967\tvalid_0's f1_score: 0.712763\n",
      "[10]\tvalid_0's multi_logloss: 1.03067\tvalid_0's f1_score: 0.703565\n",
      "[20]\tvalid_0's multi_logloss: 0.982539\tvalid_0's f1_score: 0.708889\n",
      "[20]\tvalid_0's multi_logloss: 0.984798\tvalid_0's f1_score: 0.699881\n",
      "[20]\tvalid_0's multi_logloss: 0.98246\tvalid_0's f1_score: 0.709912\n",
      "[20]\tvalid_0's multi_logloss: 0.984798\tvalid_0's f1_score: 0.699881\n",
      "[20]\tvalid_0's multi_logloss: 0.982539\tvalid_0's f1_score: 0.708889\n",
      "[30]\tvalid_0's multi_logloss: 0.939526\tvalid_0's f1_score: 0.712169\n",
      "[30]\tvalid_0's multi_logloss: 0.9424\tvalid_0's f1_score: 0.705096\n",
      "[30]\tvalid_0's multi_logloss: 0.939526\tvalid_0's f1_score: 0.712169\n",
      "[30]\tvalid_0's multi_logloss: 0.9424\tvalid_0's f1_score: 0.705096\n",
      "[30]\tvalid_0's multi_logloss: 0.938652\tvalid_0's f1_score: 0.709847\n",
      "[20]\tvalid_0's multi_logloss: 0.97378\tvalid_0's f1_score: 0.724065\n",
      "[20]\tvalid_0's multi_logloss: 0.973651\tvalid_0's f1_score: 0.718699\n",
      "[20]\tvalid_0's multi_logloss: 0.975443\tvalid_0's f1_score: 0.713772\n",
      "[40]\tvalid_0's multi_logloss: 0.90325\tvalid_0's f1_score: 0.715444\n",
      "[40]\tvalid_0's multi_logloss: 0.906693\tvalid_0's f1_score: 0.706388\n",
      "[40]\tvalid_0's multi_logloss: 0.901844\tvalid_0's f1_score: 0.712676[40]\tvalid_0's multi_logloss: 0.906693\tvalid_0's f1_score: 0.706388\n",
      "\n",
      "[40]\tvalid_0's multi_logloss: 0.90325\tvalid_0's f1_score: 0.715444\n",
      "[30]\tvalid_0's multi_logloss: 0.926994\tvalid_0's f1_score: 0.727047\n",
      "[30]\tvalid_0's multi_logloss: 0.927572\tvalid_0's f1_score: 0.722172\n",
      "[30]\tvalid_0's multi_logloss: 0.930052\tvalid_0's f1_score: 0.720096\n",
      "[50]\tvalid_0's multi_logloss: 0.871968\tvalid_0's f1_score: 0.720426\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871968\tvalid_0's f1_score: 0.720426\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.87057\tvalid_0's f1_score: 0.715024\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.87057\tvalid_0's f1_score: 0.715024\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.871968\tvalid_0's f1_score: 0.720426\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.845356\tvalid_0's f1_score: 0.720476\n",
      "[60]\tvalid_0's multi_logloss: 0.849849\tvalid_0's f1_score: 0.707208\n",
      "[40]\tvalid_0's multi_logloss: 0.888232\tvalid_0's f1_score: 0.729674\n",
      "[40]\tvalid_0's multi_logloss: 0.888563\tvalid_0's f1_score: 0.726303\n",
      "[40]\tvalid_0's multi_logloss: 0.891953\tvalid_0's f1_score: 0.722802\n",
      "[10]\tvalid_0's multi_logloss: 1.03478\tvalid_0's f1_score: 0.707675\n",
      "[70]\tvalid_0's multi_logloss: 0.826725\tvalid_0's f1_score: 0.710569\n",
      "[70]\tvalid_0's multi_logloss: 0.821935\tvalid_0's f1_score: 0.72119\n",
      "[10]\tvalid_0's multi_logloss: 1.02967\tvalid_0's f1_score: 0.712763\n",
      "[10]\tvalid_0's multi_logloss: 1.03067\tvalid_0's f1_score: 0.703565\n",
      "[20]\tvalid_0's multi_logloss: 0.98246\tvalid_0's f1_score: 0.709912\n",
      "[50]\tvalid_0's multi_logloss: 0.855217\tvalid_0's f1_score: 0.729121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.855217\tvalid_0's f1_score: 0.729121\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.85518\tvalid_0's f1_score: 0.730908\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.85518\tvalid_0's f1_score: 0.730908\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.859441\tvalid_0's f1_score: 0.7239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.859441\tvalid_0's f1_score: 0.7239\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.801463\tvalid_0's f1_score: 0.72461\n",
      "[80]\tvalid_0's multi_logloss: 0.806298\tvalid_0's f1_score: 0.713166\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.938652\tvalid_0's f1_score: 0.709847\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.973651\tvalid_0's f1_score: 0.718699\n",
      "[20]\tvalid_0's multi_logloss: 0.975443\tvalid_0's f1_score: 0.713772\n",
      "[90]\tvalid_0's multi_logloss: 0.78797\tvalid_0's f1_score: 0.717341\n",
      "[90]\tvalid_0's multi_logloss: 0.782915\tvalid_0's f1_score: 0.726718\n",
      "[10]\tvalid_0's multi_logloss: 1.03587\tvalid_0's f1_score: 0.692414\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.701491\n",
      "[40]\tvalid_0's multi_logloss: 0.901844\tvalid_0's f1_score: 0.712676\n",
      "[100]\tvalid_0's multi_logloss: 0.766581\tvalid_0's f1_score: 0.72888\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.766581\tvalid_0's f1_score: 0.72888\n",
      "[100]\tvalid_0's multi_logloss: 0.77169\tvalid_0's f1_score: 0.720342\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.77169\tvalid_0's f1_score: 0.720342\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.02989\tvalid_0's f1_score: 0.722368\n",
      "[30]\tvalid_0's multi_logloss: 0.927572\tvalid_0's f1_score: 0.722172\n",
      "[20]\tvalid_0's multi_logloss: 0.984828\tvalid_0's f1_score: 0.697434\n",
      "[30]\tvalid_0's multi_logloss: 0.930052\tvalid_0's f1_score: 0.720096\n",
      "[20]\tvalid_0's multi_logloss: 0.982495\tvalid_0's f1_score: 0.706137\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[50]\tvalid_0's multi_logloss: 0.87057\tvalid_0's f1_score: 0.715024\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.942626\tvalid_0's f1_score: 0.702126\n",
      "[30]\tvalid_0's multi_logloss: 0.939305\tvalid_0's f1_score: 0.710583\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.706372\n",
      "[60]\tvalid_0's multi_logloss: 0.844035\tvalid_0's f1_score: 0.717295\n",
      "[20]\tvalid_0's multi_logloss: 0.97378\tvalid_0's f1_score: 0.724065\n",
      "[40]\tvalid_0's multi_logloss: 0.888563\tvalid_0's f1_score: 0.726303\n",
      "[40]\tvalid_0's multi_logloss: 0.891953\tvalid_0's f1_score: 0.722802\n",
      "[10]\tvalid_0's multi_logloss: 1.03105\tvalid_0's f1_score: 0.703965\n",
      "[40]\tvalid_0's multi_logloss: 0.906839\tvalid_0's f1_score: 0.704673\n",
      "[40]\tvalid_0's multi_logloss: 0.902946\tvalid_0's f1_score: 0.714341\n",
      "[20]\tvalid_0's multi_logloss: 0.982541\tvalid_0's f1_score: 0.707898\n",
      "[70]\tvalid_0's multi_logloss: 0.821111\tvalid_0's f1_score: 0.719446\n",
      "[30]\tvalid_0's multi_logloss: 0.926994\tvalid_0's f1_score: 0.727047\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.939033\tvalid_0's f1_score: 0.712583\n",
      "[50]\tvalid_0's multi_logloss: 0.85518\tvalid_0's f1_score: 0.730908\n",
      "[80]\tvalid_0's multi_logloss: 0.800378\tvalid_0's f1_score: 0.725367\n",
      "[50]\tvalid_0's multi_logloss: 0.859441\tvalid_0's f1_score: 0.7239\n",
      "[20]\tvalid_0's multi_logloss: 0.975922\tvalid_0's f1_score: 0.709556\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's multi_logloss: 0.881631\tvalid_0's f1_score: 0.725462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.902364\tvalid_0's f1_score: 0.710959\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.935142\tvalid_0's f1_score: 0.713212\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.78201\tvalid_0's f1_score: 0.72854\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[40]\tvalid_0's multi_logloss: 0.888232\tvalid_0's f1_score: 0.729674\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.826675\tvalid_0's f1_score: 0.733424\n",
      "[30]\tvalid_0's multi_logloss: 0.930602\tvalid_0's f1_score: 0.715839\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.765901\tvalid_0's f1_score: 0.727778\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.765901\tvalid_0's f1_score: 0.727778\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.02984\tvalid_0's f1_score: 0.716098\n",
      "[10]\tvalid_0's multi_logloss: 1.03064\tvalid_0's f1_score: 0.720553\n",
      "[10]\tvalid_0's multi_logloss: 1.03587\tvalid_0's f1_score: 0.692414\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.701491\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.855217\tvalid_0's f1_score: 0.729121\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 0.888232\tvalid_0's f1_score: 0.729674\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[70]\tvalid_0's multi_logloss: 0.802074\tvalid_0's f1_score: 0.734476\n",
      "[20]\tvalid_0's multi_logloss: 0.984828\tvalid_0's f1_score: 0.697434\n",
      "[40]\tvalid_0's multi_logloss: 0.89279\tvalid_0's f1_score: 0.717607\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[20]\tvalid_0's multi_logloss: 0.974053\tvalid_0's f1_score: 0.718962\n",
      "[20]\tvalid_0's multi_logloss: 0.975078\tvalid_0's f1_score: 0.7203\n",
      "[20]\tvalid_0's multi_logloss: 0.982495\tvalid_0's f1_score: 0.706137\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.706372\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.942626\tvalid_0's f1_score: 0.702126\n",
      "[30]\tvalid_0's multi_logloss: 0.939305\tvalid_0's f1_score: 0.710583\n",
      "[80]\tvalid_0's multi_logloss: 0.780695\tvalid_0's f1_score: 0.735158\n",
      "[20]\tvalid_0's multi_logloss: 0.982541\tvalid_0's f1_score: 0.707898\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 0.989619\tvalid_0's f1_score: 0.720154\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.860105\tvalid_0's f1_score: 0.721989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.860105\tvalid_0's f1_score: 0.721989\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.906839\tvalid_0's f1_score: 0.704673\n",
      "[10]\tvalid_0's multi_logloss: 1.03105\tvalid_0's f1_score: 0.703965\n",
      "[30]\tvalid_0's multi_logloss: 0.928774\tvalid_0's f1_score: 0.722838\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.902946\tvalid_0's f1_score: 0.714341\n",
      "[30]\tvalid_0's multi_logloss: 0.939033\tvalid_0's f1_score: 0.712583\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "[90]\tvalid_0's multi_logloss: 0.761718\tvalid_0's f1_score: 0.736719\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "[40]\tvalid_0's multi_logloss: 0.902364\tvalid_0's f1_score: 0.710959\n",
      "[20]\tvalid_0's multi_logloss: 0.975922\tvalid_0's f1_score: 0.709556\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.935142\tvalid_0's f1_score: 0.713212\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.890402\tvalid_0's f1_score: 0.724997\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 1.02984\tvalid_0's f1_score: 0.716098\n",
      "[10]\tvalid_0's multi_logloss: 1.03064\tvalid_0's f1_score: 0.720553\n",
      "[60]\tvalid_0's multi_logloss: 0.849973\tvalid_0's f1_score: 0.708823\n",
      "[60]\tvalid_0's multi_logloss: 0.8447\tvalid_0's f1_score: 0.720426\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.744647\tvalid_0's f1_score: 0.739651\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.744647\tvalid_0's f1_score: 0.739651\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[70]\tvalid_0's multi_logloss: 0.826682\tvalid_0's f1_score: 0.711075\n",
      "[30]\tvalid_0's multi_logloss: 0.930602\tvalid_0's f1_score: 0.715839\n",
      "[50]\tvalid_0's multi_logloss: 0.857488\tvalid_0's f1_score: 0.724606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.857488\tvalid_0's f1_score: 0.724606\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.974053\tvalid_0's f1_score: 0.718962\n",
      "[20]\tvalid_0's multi_logloss: 0.975078\tvalid_0's f1_score: 0.7203\n",
      "[70]\tvalid_0's multi_logloss: 0.821251\tvalid_0's f1_score: 0.721164\n",
      "[10]\tvalid_0's multi_logloss: 1.03585\tvalid_0's f1_score: 0.692986\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.806405\tvalid_0's f1_score: 0.712538\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.800525\tvalid_0's f1_score: 0.725831\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's multi_logloss: 0.989619\tvalid_0's f1_score: 0.720154\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.984798\tvalid_0's f1_score: 0.699881\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 1.03466\tvalid_0's f1_score: 0.701326\n",
      "[40]\tvalid_0's multi_logloss: 0.89279\tvalid_0's f1_score: 0.717607\n",
      "[90]\tvalid_0's multi_logloss: 0.788404\tvalid_0's f1_score: 0.715025\n",
      "[30]\tvalid_0's multi_logloss: 0.928774\tvalid_0's f1_score: 0.722838\n",
      "[10]\tvalid_0's multi_logloss: 1.03478\tvalid_0's f1_score: 0.707675\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[90]\tvalid_0's multi_logloss: 0.781937\tvalid_0's f1_score: 0.728831\n",
      "[30]\tvalid_0's multi_logloss: 0.9424\tvalid_0's f1_score: 0.705096\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.982539\tvalid_0's f1_score: 0.708889\n",
      "[100]\tvalid_0's multi_logloss: 0.77204\tvalid_0's f1_score: 0.717575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.77204\tvalid_0's f1_score: 0.717575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.98246\tvalid_0's f1_score: 0.709912\n",
      "[50]\tvalid_0's multi_logloss: 0.860105\tvalid_0's f1_score: 0.721989\n",
      "[100]\tvalid_0's multi_logloss: 0.765473\tvalid_0's f1_score: 0.730583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.765473\tvalid_0's f1_score: 0.730583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.906693\tvalid_0's f1_score: 0.706388\n",
      "[40]\tvalid_0's multi_logloss: 0.890402\tvalid_0's f1_score: 0.724997\n",
      "[30]\tvalid_0's multi_logloss: 0.939526\tvalid_0's f1_score: 0.712169\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[10]\tvalid_0's multi_logloss: 1.03059\tvalid_0's f1_score: 0.701749\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.938652\tvalid_0's f1_score: 0.709847\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.90325\tvalid_0's f1_score: 0.715444\n",
      "[60]\tvalid_0's multi_logloss: 0.832096\tvalid_0's f1_score: 0.722799\n",
      "[40]\tvalid_0's multi_logloss: 0.901844\tvalid_0's f1_score: 0.712676\n",
      "[50]\tvalid_0's multi_logloss: 0.857488\tvalid_0's f1_score: 0.724606\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[10]\tvalid_0's multi_logloss: 1.02965\tvalid_0's f1_score: 0.713298\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.883445\tvalid_0's f1_score: 0.726739\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.975354\tvalid_0's f1_score: 0.714405\n",
      "[50]\tvalid_0's multi_logloss: 0.871891\tvalid_0's f1_score: 0.72038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871891\tvalid_0's f1_score: 0.72038\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 1.02987\tvalid_0's f1_score: 0.720879\n",
      "[50]\tvalid_0's multi_logloss: 0.870568\tvalid_0's f1_score: 0.714687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.870568\tvalid_0's f1_score: 0.714687\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[10]\tvalid_0's multi_logloss: 1.03585\tvalid_0's f1_score: 0.692986\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.807926\tvalid_0's f1_score: 0.722292\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[20]\tvalid_0's multi_logloss: 0.973608\tvalid_0's f1_score: 0.719272\n",
      "[30]\tvalid_0's multi_logloss: 0.929827\tvalid_0's f1_score: 0.71892\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03466\tvalid_0's f1_score: 0.701326\n",
      "[20]\tvalid_0's multi_logloss: 0.984798\tvalid_0's f1_score: 0.699881\n",
      "[20]\tvalid_0's multi_logloss: 0.973587\tvalid_0's f1_score: 0.726567\n",
      "[10]\tvalid_0's multi_logloss: 1.03478\tvalid_0's f1_score: 0.707675\n",
      "[80]\tvalid_0's multi_logloss: 0.786513\tvalid_0's f1_score: 0.727018\n",
      "[20]\tvalid_0's multi_logloss: 0.982539\tvalid_0's f1_score: 0.708889\n",
      "[30]\tvalid_0's multi_logloss: 0.9424\tvalid_0's f1_score: 0.705096\n",
      "[20]\tvalid_0's multi_logloss: 0.98246\tvalid_0's f1_score: 0.709912\n",
      "[10]\tvalid_0's multi_logloss: 1.03059\tvalid_0's f1_score: 0.701749\n",
      "[30]\tvalid_0's multi_logloss: 0.927416\tvalid_0's f1_score: 0.721729\n",
      "[40]\tvalid_0's multi_logloss: 0.891923\tvalid_0's f1_score: 0.722931\n",
      "[30]\tvalid_0's multi_logloss: 0.927009\tvalid_0's f1_score: 0.728688\n",
      "[30]\tvalid_0's multi_logloss: 0.939526\tvalid_0's f1_score: 0.712169\n",
      "[40]\tvalid_0's multi_logloss: 0.906693\tvalid_0's f1_score: 0.706388\n",
      "[30]\tvalid_0's multi_logloss: 0.938652\tvalid_0's f1_score: 0.709847\n",
      "[90]\tvalid_0's multi_logloss: 0.76741\tvalid_0's f1_score: 0.729722\n",
      "[20]\tvalid_0's multi_logloss: 0.975354\tvalid_0's f1_score: 0.714405\n",
      "[40]\tvalid_0's multi_logloss: 0.888316\tvalid_0's f1_score: 0.727084\n",
      "[50]\tvalid_0's multi_logloss: 0.859506\tvalid_0's f1_score: 0.724748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.859506\tvalid_0's f1_score: 0.724748\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.90325\tvalid_0's f1_score: 0.715444\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.876323\tvalid_0's f1_score: 0.705899\n",
      "[40]\tvalid_0's multi_logloss: 0.901844\tvalid_0's f1_score: 0.712676\n",
      "[40]\tvalid_0's multi_logloss: 0.888189\tvalid_0's f1_score: 0.729861\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[100]\tvalid_0's multi_logloss: 0.750537\tvalid_0's f1_score: 0.733937\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.750537\tvalid_0's f1_score: 0.733937\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.871891\tvalid_0's f1_score: 0.72038\n",
      "[60]\tvalid_0's multi_logloss: 0.849849\tvalid_0's f1_score: 0.707208\n",
      "[50]\tvalid_0's multi_logloss: 0.870568\tvalid_0's f1_score: 0.714687\n",
      "[30]\tvalid_0's multi_logloss: 0.929827\tvalid_0's f1_score: 0.71892\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 0.899175\tvalid_0's f1_score: 0.730161\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.85513\tvalid_0's f1_score: 0.732076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.85513\tvalid_0's f1_score: 0.732076\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.845113\tvalid_0's f1_score: 0.721356\n",
      "[70]\tvalid_0's multi_logloss: 0.826584\tvalid_0's f1_score: 0.711194\n",
      "[60]\tvalid_0's multi_logloss: 0.844011\tvalid_0's f1_score: 0.717257\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.02965\tvalid_0's f1_score: 0.713298\n",
      "[40]\tvalid_0's multi_logloss: 0.891923\tvalid_0's f1_score: 0.722931\n",
      "[70]\tvalid_0's multi_logloss: 0.821884\tvalid_0's f1_score: 0.722917\n",
      "[80]\tvalid_0's multi_logloss: 0.806214\tvalid_0's f1_score: 0.714015\n",
      "[70]\tvalid_0's multi_logloss: 0.821057\tvalid_0's f1_score: 0.721179\n",
      "[10]\tvalid_0's multi_logloss: 1.03587\tvalid_0's f1_score: 0.692414\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.701491\n",
      "[10]\tvalid_0's multi_logloss: 1.02987\tvalid_0's f1_score: 0.720879\n",
      "[80]\tvalid_0's multi_logloss: 0.80144\tvalid_0's f1_score: 0.72584\n",
      "[20]\tvalid_0's multi_logloss: 0.973608\tvalid_0's f1_score: 0.719272\n",
      "[90]\tvalid_0's multi_logloss: 0.787983\tvalid_0's f1_score: 0.71665\n",
      "[80]\tvalid_0's multi_logloss: 0.80012\tvalid_0's f1_score: 0.725463\n",
      "[20]\tvalid_0's multi_logloss: 0.984828\tvalid_0's f1_score: 0.697434\n",
      "[20]\tvalid_0's multi_logloss: 0.982495\tvalid_0's f1_score: 0.706137\n",
      "[50]\tvalid_0's multi_logloss: 0.859506\tvalid_0's f1_score: 0.724748\n",
      "[20]\tvalid_0's multi_logloss: 0.973587\tvalid_0's f1_score: 0.726567\n",
      "[90]\tvalid_0's multi_logloss: 0.783089\tvalid_0's f1_score: 0.726308\n",
      "[100]\tvalid_0's multi_logloss: 0.771717\tvalid_0's f1_score: 0.719206\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.771717\tvalid_0's f1_score: 0.719206\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.78199\tvalid_0's f1_score: 0.726437\n",
      "[30]\tvalid_0's multi_logloss: 0.942626\tvalid_0's f1_score: 0.702126\n",
      "[30]\tvalid_0's multi_logloss: 0.939305\tvalid_0's f1_score: 0.710583\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's multi_logloss: 0.797588\tvalid_0's f1_score: 0.726688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.927416\tvalid_0's f1_score: 0.721729\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.906839\tvalid_0's f1_score: 0.704673\n",
      "[60]\tvalid_0's multi_logloss: 0.831854\tvalid_0's f1_score: 0.724612\n",
      "[100]\tvalid_0's multi_logloss: 0.76587\tvalid_0's f1_score: 0.727407\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.76587\tvalid_0's f1_score: 0.727407\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.902946\tvalid_0's f1_score: 0.714341\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.927009\tvalid_0's f1_score: 0.728688\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.706372\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.888316\tvalid_0's f1_score: 0.727084\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.03101\tvalid_0's f1_score: 0.7023\n",
      "[70]\tvalid_0's multi_logloss: 0.807733\tvalid_0's f1_score: 0.725243\n",
      "[20]\tvalid_0's multi_logloss: 0.982541\tvalid_0's f1_score: 0.707898\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.888189\tvalid_0's f1_score: 0.729861\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.819439\tvalid_0's f1_score: 0.726522\n",
      "[10]\tvalid_0's multi_logloss: 1.02984\tvalid_0's f1_score: 0.715176\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.85513\tvalid_0's f1_score: 0.732076\n",
      "[30]\tvalid_0's multi_logloss: 0.939033\tvalid_0's f1_score: 0.712583\n",
      "[10]\tvalid_0's multi_logloss: 1.03587\tvalid_0's f1_score: 0.692414\n",
      "[20]\tvalid_0's multi_logloss: 0.975947\tvalid_0's f1_score: 0.711207\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's multi_logloss: 0.899175\tvalid_0's f1_score: 0.730161\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.0307\tvalid_0's f1_score: 0.719845\n",
      "[40]\tvalid_0's multi_logloss: 0.902352\tvalid_0's f1_score: 0.711258\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.935142\tvalid_0's f1_score: 0.713212\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.984828\tvalid_0's f1_score: 0.697434\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[20]\tvalid_0's multi_logloss: 0.974068\tvalid_0's f1_score: 0.718345\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.701491\n",
      "[60]\tvalid_0's multi_logloss: 0.826518\tvalid_0's f1_score: 0.733765\n",
      "[30]\tvalid_0's multi_logloss: 0.930711\tvalid_0's f1_score: 0.716762\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.942626\tvalid_0's f1_score: 0.702126\n",
      "[10]\tvalid_0's multi_logloss: 1.0347\tvalid_0's f1_score: 0.706372\n",
      "[20]\tvalid_0's multi_logloss: 0.975209\tvalid_0's f1_score: 0.72114\n",
      "[20]\tvalid_0's multi_logloss: 0.982495\tvalid_0's f1_score: 0.706137\n",
      "[30]\tvalid_0's multi_logloss: 0.927929\tvalid_0's f1_score: 0.720512\n",
      "[40]\tvalid_0's multi_logloss: 0.906839\tvalid_0's f1_score: 0.704673\n",
      "[70]\tvalid_0's multi_logloss: 0.80212\tvalid_0's f1_score: 0.735047\n",
      "[20]\tvalid_0's multi_logloss: 0.982541\tvalid_0's f1_score: 0.707898\n",
      "[40]\tvalid_0's multi_logloss: 0.892875\tvalid_0's f1_score: 0.718481\n",
      "[10]\tvalid_0's multi_logloss: 1.03101\tvalid_0's f1_score: 0.7023\n",
      "[30]\tvalid_0's multi_logloss: 0.939305\tvalid_0's f1_score: 0.710583\n",
      "[30]\tvalid_0's multi_logloss: 0.928641\tvalid_0's f1_score: 0.721381\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 0.970167\tvalid_0's f1_score: 0.723381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.876317\tvalid_0's f1_score: 0.706032\n",
      "[30]\tvalid_0's multi_logloss: 0.939033\tvalid_0's f1_score: 0.712583\n",
      "[40]\tvalid_0's multi_logloss: 0.888587\tvalid_0's f1_score: 0.724623\n",
      "[40]\tvalid_0's multi_logloss: 0.902946\tvalid_0's f1_score: 0.714341\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[80]\tvalid_0's multi_logloss: 0.780443\tvalid_0's f1_score: 0.736289\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.860372\tvalid_0's f1_score: 0.71882\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.860372\tvalid_0's f1_score: 0.71882\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.975947\tvalid_0's f1_score: 0.711207\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.849973\tvalid_0's f1_score: 0.708823\n",
      "[40]\tvalid_0's multi_logloss: 0.902352\tvalid_0's f1_score: 0.711258\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.935142\tvalid_0's f1_score: 0.713212\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.871512\tvalid_0's f1_score: 0.717541\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.855234\tvalid_0's f1_score: 0.726741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.855234\tvalid_0's f1_score: 0.726741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[70]\tvalid_0's multi_logloss: 0.826682\tvalid_0's f1_score: 0.711075\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.782529\tvalid_0's f1_score: 0.736583\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.02984\tvalid_0's f1_score: 0.715176\n",
      "[60]\tvalid_0's multi_logloss: 0.8447\tvalid_0's f1_score: 0.720426\n",
      "[30]\tvalid_0's multi_logloss: 0.930711\tvalid_0's f1_score: 0.716762\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[80]\tvalid_0's multi_logloss: 0.806409\tvalid_0's f1_score: 0.71224\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.768229\tvalid_0's f1_score: 0.71852\n",
      "[10]\tvalid_0's multi_logloss: 1.0307\tvalid_0's f1_score: 0.719845\n",
      "[70]\tvalid_0's multi_logloss: 0.821251\tvalid_0's f1_score: 0.721164\n",
      "[20]\tvalid_0's multi_logloss: 0.974068\tvalid_0's f1_score: 0.718345\n",
      "[10]\tvalid_0's multi_logloss: 0.763916\tvalid_0's f1_score: 0.729016\n",
      "[10]\tvalid_0's multi_logloss: 0.761122\tvalid_0's f1_score: 0.726751\n",
      "[90]\tvalid_0's multi_logloss: 0.788435\tvalid_0's f1_score: 0.714601\n",
      "[40]\tvalid_0's multi_logloss: 0.892875\tvalid_0's f1_score: 0.718481\n",
      "[20]\tvalid_0's multi_logloss: 0.668206\tvalid_0's f1_score: 0.743681\n",
      "[80]\tvalid_0's multi_logloss: 0.800554\tvalid_0's f1_score: 0.72579\n",
      "[20]\tvalid_0's multi_logloss: 0.666011\tvalid_0's f1_score: 0.746922\n",
      "[20]\tvalid_0's multi_logloss: 0.975209\tvalid_0's f1_score: 0.72114\n",
      "[20]\tvalid_0's multi_logloss: 0.662182\tvalid_0's f1_score: 0.748906\n",
      "[100]\tvalid_0's multi_logloss: 0.772454\tvalid_0's f1_score: 0.716905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.772454\tvalid_0's f1_score: 0.716905\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.616588\tvalid_0's f1_score: 0.761652\n",
      "[90]\tvalid_0's multi_logloss: 0.781989\tvalid_0's f1_score: 0.728828\n",
      "[30]\tvalid_0's multi_logloss: 0.927929\tvalid_0's f1_score: 0.720512\n",
      "[50]\tvalid_0's multi_logloss: 0.860372\tvalid_0's f1_score: 0.71882\n",
      "[30]\tvalid_0's multi_logloss: 0.618373\tvalid_0's f1_score: 0.755105\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[30]\tvalid_0's multi_logloss: 0.612469\tvalid_0's f1_score: 0.760031\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.586445\tvalid_0's f1_score: 0.767844\n",
      "[100]\tvalid_0's multi_logloss: 0.765719\tvalid_0's f1_score: 0.730971\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.765719\tvalid_0's f1_score: 0.730971\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.928641\tvalid_0's f1_score: 0.721381\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 0.970167\tvalid_0's f1_score: 0.723381\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.589462\tvalid_0's f1_score: 0.763865\n",
      "[40]\tvalid_0's multi_logloss: 0.888587\tvalid_0's f1_score: 0.724623\n",
      "[40]\tvalid_0's multi_logloss: 0.584862\tvalid_0's f1_score: 0.765717\n",
      "[50]\tvalid_0's multi_logloss: 0.568728\tvalid_0's f1_score: 0.777744\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.568728\tvalid_0's f1_score: 0.777744\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[60]\tvalid_0's multi_logloss: 0.83263\tvalid_0's f1_score: 0.722584\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[10]\tvalid_0's multi_logloss: 0.747363\tvalid_0's f1_score: 0.733728\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.573852\tvalid_0's f1_score: 0.774548\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.573852\tvalid_0's f1_score: 0.774548\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.566619\tvalid_0's f1_score: 0.773948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.566619\tvalid_0's f1_score: 0.773948\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.837814\tvalid_0's f1_score: 0.723216\n",
      "[50]\tvalid_0's multi_logloss: 0.855234\tvalid_0's f1_score: 0.726741\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[10]\tvalid_0's multi_logloss: 0.741041\tvalid_0's f1_score: 0.739923\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.768229\tvalid_0's f1_score: 0.71852\n",
      "[10]\tvalid_0's multi_logloss: 0.741939\tvalid_0's f1_score: 0.74026\n",
      "[20]\tvalid_0's multi_logloss: 0.647358\tvalid_0's f1_score: 0.752408\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.763916\tvalid_0's f1_score: 0.729016\n",
      "[10]\tvalid_0's multi_logloss: 0.761122\tvalid_0's f1_score: 0.726751\n",
      "[20]\tvalid_0's multi_logloss: 0.668206\tvalid_0's f1_score: 0.743681\n",
      "[60]\tvalid_0's multi_logloss: 0.827017\tvalid_0's f1_score: 0.730551\n",
      "[20]\tvalid_0's multi_logloss: 0.643677\tvalid_0's f1_score: 0.753275\n",
      "[20]\tvalid_0's multi_logloss: 0.640673\tvalid_0's f1_score: 0.754369\n",
      "[30]\tvalid_0's multi_logloss: 0.594737\tvalid_0's f1_score: 0.770755\n",
      "[20]\tvalid_0's multi_logloss: 0.666011\tvalid_0's f1_score: 0.746922\n",
      "[20]\tvalid_0's multi_logloss: 0.662182\tvalid_0's f1_score: 0.748906\n",
      "[10]\tvalid_0's multi_logloss: 0.747363\tvalid_0's f1_score: 0.733728\n",
      "[30]\tvalid_0's multi_logloss: 0.616588\tvalid_0's f1_score: 0.761652\n",
      "[70]\tvalid_0's multi_logloss: 0.802702\tvalid_0's f1_score: 0.73313\n",
      "[30]\tvalid_0's multi_logloss: 0.618373\tvalid_0's f1_score: 0.755105\n",
      "[30]\tvalid_0's multi_logloss: 0.612469\tvalid_0's f1_score: 0.760031\n",
      "[30]\tvalid_0's multi_logloss: 0.597492\tvalid_0's f1_score: 0.763886\n",
      "[40]\tvalid_0's multi_logloss: 0.586445\tvalid_0's f1_score: 0.767844\n",
      "[30]\tvalid_0's multi_logloss: 0.591088\tvalid_0's f1_score: 0.766488\n",
      "[40]\tvalid_0's multi_logloss: 0.567802\tvalid_0's f1_score: 0.775295\n",
      "[20]\tvalid_0's multi_logloss: 0.647358\tvalid_0's f1_score: 0.752408\n",
      "[40]\tvalid_0's multi_logloss: 0.589462\tvalid_0's f1_score: 0.763865\n",
      "[40]\tvalid_0's multi_logloss: 0.584862\tvalid_0's f1_score: 0.765717\n",
      "[50]\tvalid_0's multi_logloss: 0.568728\tvalid_0's f1_score: 0.777744\n",
      "[80]\tvalid_0's multi_logloss: 0.781175\tvalid_0's f1_score: 0.735605\n",
      "[40]\tvalid_0's multi_logloss: 0.571425\tvalid_0's f1_score: 0.777288\n",
      "[50]\tvalid_0's multi_logloss: 0.573852\tvalid_0's f1_score: 0.774548\n",
      "[50]\tvalid_0's multi_logloss: 0.566619\tvalid_0's f1_score: 0.773948\n",
      "[40]\tvalid_0's multi_logloss: 0.564537\tvalid_0's f1_score: 0.778304\n",
      "[50]\tvalid_0's multi_logloss: 0.55198\tvalid_0's f1_score: 0.782736\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.55198\tvalid_0's f1_score: 0.782736\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[60]\tvalid_0's multi_logloss: 0.558032\tvalid_0's f1_score: 0.780328\n",
      "[30]\tvalid_0's multi_logloss: 0.594737\tvalid_0's f1_score: 0.770755\n",
      "[60]\tvalid_0's multi_logloss: 0.564896\tvalid_0's f1_score: 0.778008\n",
      "[90]\tvalid_0's multi_logloss: 0.762242\tvalid_0's f1_score: 0.739793\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[60]\tvalid_0's multi_logloss: 0.555505\tvalid_0's f1_score: 0.776502\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.550866\tvalid_0's f1_score: 0.785564\n",
      "[50]\tvalid_0's multi_logloss: 0.557698\tvalid_0's f1_score: 0.784556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.557698\tvalid_0's f1_score: 0.784556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.548224\tvalid_0's f1_score: 0.782862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.548224\tvalid_0's f1_score: 0.782862\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[70]\tvalid_0's multi_logloss: 0.558047\tvalid_0's f1_score: 0.78391\n",
      "[40]\tvalid_0's multi_logloss: 0.567802\tvalid_0's f1_score: 0.775295\n",
      "[70]\tvalid_0's multi_logloss: 0.547917\tvalid_0's f1_score: 0.783169\n",
      "[80]\tvalid_0's multi_logloss: 0.546634\tvalid_0's f1_score: 0.788532\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.745038\tvalid_0's f1_score: 0.741178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.745038\tvalid_0's f1_score: 0.741178\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 0.741041\tvalid_0's f1_score: 0.739923\n",
      "[80]\tvalid_0's multi_logloss: 0.553345\tvalid_0's f1_score: 0.785001\n",
      "[80]\tvalid_0's multi_logloss: 0.542412\tvalid_0's f1_score: 0.783723\n",
      "[90]\tvalid_0's multi_logloss: 0.541814\tvalid_0's f1_score: 0.79001\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.769623\tvalid_0's f1_score: 0.716068\n",
      "[50]\tvalid_0's multi_logloss: 0.55198\tvalid_0's f1_score: 0.782736\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 0.544704\tvalid_0's f1_score: 0.790415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 0.741939\tvalid_0's f1_score: 0.74026\n",
      "[90]\tvalid_0's multi_logloss: 0.548478\tvalid_0's f1_score: 0.788539\n",
      "[90]\tvalid_0's multi_logloss: 0.53746\tvalid_0's f1_score: 0.79148\n",
      "[20]\tvalid_0's multi_logloss: 0.643677\tvalid_0's f1_score: 0.753275\n",
      "[10]\tvalid_0's multi_logloss: 0.763112\tvalid_0's f1_score: 0.72623\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[20]\tvalid_0's multi_logloss: 0.665863\tvalid_0's f1_score: 0.746329\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.546127\tvalid_0's f1_score: 0.789226\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.546127\tvalid_0's f1_score: 0.789226\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[100]\tvalid_0's multi_logloss: 0.534207\tvalid_0's f1_score: 0.792953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.534207\tvalid_0's f1_score: 0.792953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.542582\tvalid_0's f1_score: 0.786132\n",
      "[20]\tvalid_0's multi_logloss: 0.6628\tvalid_0's f1_score: 0.746662\n",
      "[10]\tvalid_0's multi_logloss: 0.761587\tvalid_0's f1_score: 0.726213\n",
      "[30]\tvalid_0's multi_logloss: 0.615355\tvalid_0's f1_score: 0.759773\n",
      "[20]\tvalid_0's multi_logloss: 0.640673\tvalid_0's f1_score: 0.754369\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[30]\tvalid_0's multi_logloss: 0.597492\tvalid_0's f1_score: 0.763886\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.615571\tvalid_0's f1_score: 0.760865\n",
      "[20]\tvalid_0's multi_logloss: 0.660873\tvalid_0's f1_score: 0.744119\n",
      "[40]\tvalid_0's multi_logloss: 0.585559\tvalid_0's f1_score: 0.771667\n",
      "[70]\tvalid_0's multi_logloss: 0.537772\tvalid_0's f1_score: 0.789469\n",
      "[30]\tvalid_0's multi_logloss: 0.591088\tvalid_0's f1_score: 0.766488\n",
      "[40]\tvalid_0's multi_logloss: 0.588706\tvalid_0's f1_score: 0.772517\n",
      "[10]\tvalid_0's multi_logloss: 0.747616\tvalid_0's f1_score: 0.729719\n",
      "[30]\tvalid_0's multi_logloss: 0.609892\tvalid_0's f1_score: 0.761778\n",
      "[40]\tvalid_0's multi_logloss: 0.571425\tvalid_0's f1_score: 0.777288\n",
      "[10]\tvalid_0's multi_logloss: 0.741718\tvalid_0's f1_score: 0.733048\n",
      "[50]\tvalid_0's multi_logloss: 0.568606\tvalid_0's f1_score: 0.777144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.568606\tvalid_0's f1_score: 0.777144\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[50]\tvalid_0's multi_logloss: 0.574003\tvalid_0's f1_score: 0.775178\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.574003\tvalid_0's f1_score: 0.775178\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.581322\tvalid_0's f1_score: 0.771838\n",
      "[80]\tvalid_0's multi_logloss: 0.535383\tvalid_0's f1_score: 0.7898\n",
      "[40]\tvalid_0's multi_logloss: 0.564537\tvalid_0's f1_score: 0.778304\n",
      "[20]\tvalid_0's multi_logloss: 0.645381\tvalid_0's f1_score: 0.75256\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 0.536866\tvalid_0's f1_score: 0.790944\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.557698\tvalid_0's f1_score: 0.784556\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[20]\tvalid_0's multi_logloss: 0.642138\tvalid_0's f1_score: 0.75391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.564429\tvalid_0's f1_score: 0.779367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.564429\tvalid_0's f1_score: 0.779367\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.74325\tvalid_0's f1_score: 0.736503\n",
      "[10]\tvalid_0's multi_logloss: 0.769623\tvalid_0's f1_score: 0.716068\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.548224\tvalid_0's f1_score: 0.782862\n",
      "[30]\tvalid_0's multi_logloss: 0.591223\tvalid_0's f1_score: 0.769832\n",
      "[30]\tvalid_0's multi_logloss: 0.594991\tvalid_0's f1_score: 0.764322\n",
      "[60]\tvalid_0's multi_logloss: 0.549634\tvalid_0's f1_score: 0.787309\n",
      "[10]\tvalid_0's multi_logloss: 0.763112\tvalid_0's f1_score: 0.72623\n",
      "[20]\tvalid_0's multi_logloss: 0.665863\tvalid_0's f1_score: 0.746329\n",
      "[10]\tvalid_0's multi_logloss: 0.761587\tvalid_0's f1_score: 0.726213\n",
      "[20]\tvalid_0's multi_logloss: 0.642672\tvalid_0's f1_score: 0.751586\n",
      "[20]\tvalid_0's multi_logloss: 0.6628\tvalid_0's f1_score: 0.746662\n",
      "[60]\tvalid_0's multi_logloss: 0.539091\tvalid_0's f1_score: 0.788567\n",
      "[30]\tvalid_0's multi_logloss: 0.615355\tvalid_0's f1_score: 0.759773\n",
      "[40]\tvalid_0's multi_logloss: 0.562277\tvalid_0's f1_score: 0.785263\n",
      "[20]\tvalid_0's multi_logloss: 0.660873\tvalid_0's f1_score: 0.744119\n",
      "[40]\tvalid_0's multi_logloss: 0.567978\tvalid_0's f1_score: 0.778618\n",
      "[70]\tvalid_0's multi_logloss: 0.545555\tvalid_0's f1_score: 0.789552\n",
      "[30]\tvalid_0's multi_logloss: 0.615571\tvalid_0's f1_score: 0.760865\n",
      "[30]\tvalid_0's multi_logloss: 0.589171\tvalid_0's f1_score: 0.77175\n",
      "[40]\tvalid_0's multi_logloss: 0.585559\tvalid_0's f1_score: 0.771667\n",
      "[30]\tvalid_0's multi_logloss: 0.609892\tvalid_0's f1_score: 0.761778\n",
      "[70]\tvalid_0's multi_logloss: 0.533333\tvalid_0's f1_score: 0.788776\n",
      "[40]\tvalid_0's multi_logloss: 0.588706\tvalid_0's f1_score: 0.772517\n",
      "[50]\tvalid_0's multi_logloss: 0.546823\tvalid_0's f1_score: 0.786022\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.546823\tvalid_0's f1_score: 0.786022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.554004\tvalid_0's f1_score: 0.786761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.554004\tvalid_0's f1_score: 0.786761\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.542946\tvalid_0's f1_score: 0.790145\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.568606\tvalid_0's f1_score: 0.777144\n",
      "[40]\tvalid_0's multi_logloss: 0.581322\tvalid_0's f1_score: 0.771838\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[40]\tvalid_0's multi_logloss: 0.561341\tvalid_0's f1_score: 0.780276\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.574003\tvalid_0's f1_score: 0.775178\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.558493\tvalid_0's f1_score: 0.780297\n",
      "[50]\tvalid_0's multi_logloss: 0.564429\tvalid_0's f1_score: 0.779367\n",
      "[80]\tvalid_0's multi_logloss: 0.530279\tvalid_0's f1_score: 0.792822\n",
      "[90]\tvalid_0's multi_logloss: 0.542402\tvalid_0's f1_score: 0.791637\n",
      "[60]\tvalid_0's multi_logloss: 0.562854\tvalid_0's f1_score: 0.779643\n",
      "[70]\tvalid_0's multi_logloss: 0.548654\tvalid_0's f1_score: 0.786793\n",
      "[10]\tvalid_0's multi_logloss: 0.747616\tvalid_0's f1_score: 0.729719\n",
      "[60]\tvalid_0's multi_logloss: 0.553456\tvalid_0's f1_score: 0.780105\n",
      "[10]\tvalid_0's multi_logloss: 0.741718\tvalid_0's f1_score: 0.733048\n",
      "[50]\tvalid_0's multi_logloss: 0.544298\tvalid_0's f1_score: 0.78493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.544298\tvalid_0's f1_score: 0.78493\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[70]\tvalid_0's multi_logloss: 0.557174\tvalid_0's f1_score: 0.785093\n",
      "[90]\tvalid_0's multi_logloss: 0.529195\tvalid_0's f1_score: 0.79066\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.542431\tvalid_0's f1_score: 0.792561\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[80]\tvalid_0's multi_logloss: 0.544481\tvalid_0's f1_score: 0.792635\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.54461\tvalid_0's f1_score: 0.784552\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 0.529055\tvalid_0's f1_score: 0.793793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.645381\tvalid_0's f1_score: 0.75256\n",
      "[80]\tvalid_0's multi_logloss: 0.553307\tvalid_0's f1_score: 0.784705\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[20]\tvalid_0's multi_logloss: 0.642138\tvalid_0's f1_score: 0.75391\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[90]\tvalid_0's multi_logloss: 0.541083\tvalid_0's f1_score: 0.792629\n",
      "[80]\tvalid_0's multi_logloss: 0.539204\tvalid_0's f1_score: 0.78807\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.74325\tvalid_0's f1_score: 0.736503\n",
      "[90]\tvalid_0's multi_logloss: 0.5492\tvalid_0's f1_score: 0.788455\n",
      "[10]\tvalid_0's multi_logloss: 0.768576\tvalid_0's f1_score: 0.718479\n",
      "[100]\tvalid_0's multi_logloss: 0.537862\tvalid_0's f1_score: 0.792209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.537862\tvalid_0's f1_score: 0.792209\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[90]\tvalid_0's multi_logloss: 0.535361\tvalid_0's f1_score: 0.79128\n",
      "[30]\tvalid_0's multi_logloss: 0.591223\tvalid_0's f1_score: 0.769832\n",
      "[10]\tvalid_0's multi_logloss: 0.763927\tvalid_0's f1_score: 0.72719\n",
      "[30]\tvalid_0's multi_logloss: 0.594991\tvalid_0's f1_score: 0.764322\n",
      "[100]\tvalid_0's multi_logloss: 0.545614\tvalid_0's f1_score: 0.790105\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.545614\tvalid_0's f1_score: 0.790105\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.668023\tvalid_0's f1_score: 0.744999\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.535431\tvalid_0's f1_score: 0.792536\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.642672\tvalid_0's f1_score: 0.751586\n",
      "[20]\tvalid_0's multi_logloss: 0.666895\tvalid_0's f1_score: 0.743945\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[30]\tvalid_0's multi_logloss: 0.618624\tvalid_0's f1_score: 0.759848\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.562277\tvalid_0's f1_score: 0.785263\n",
      "[10]\tvalid_0's multi_logloss: 0.761157\tvalid_0's f1_score: 0.727134\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[40]\tvalid_0's multi_logloss: 0.567978\tvalid_0's f1_score: 0.778618\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.620358\tvalid_0's f1_score: 0.756274\n",
      "[40]\tvalid_0's multi_logloss: 0.588439\tvalid_0's f1_score: 0.772969\n",
      "[30]\tvalid_0's multi_logloss: 0.589171\tvalid_0's f1_score: 0.77175\n",
      "[20]\tvalid_0's multi_logloss: 0.66348\tvalid_0's f1_score: 0.744813\n",
      "[10]\tvalid_0's multi_logloss: 0.747286\tvalid_0's f1_score: 0.735323\n",
      "[40]\tvalid_0's multi_logloss: 0.592799\tvalid_0's f1_score: 0.771074\n",
      "[50]\tvalid_0's multi_logloss: 0.546823\tvalid_0's f1_score: 0.786022\n",
      "[10]\tvalid_0's multi_logloss: 0.740224\tvalid_0's f1_score: 0.736096\n",
      "[50]\tvalid_0's multi_logloss: 0.554004\tvalid_0's f1_score: 0.786761\n",
      "[50]\tvalid_0's multi_logloss: 0.572798\tvalid_0's f1_score: 0.776917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.572798\tvalid_0's f1_score: 0.776917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.613254\tvalid_0's f1_score: 0.757822\n",
      "[50]\tvalid_0's multi_logloss: 0.575415\tvalid_0's f1_score: 0.776639\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.575415\tvalid_0's f1_score: 0.776639\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.561341\tvalid_0's f1_score: 0.780276\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 0.551017\tvalid_0's f1_score: 0.789108\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.648029\tvalid_0's f1_score: 0.750605\n",
      "[40]\tvalid_0's multi_logloss: 0.586323\tvalid_0's f1_score: 0.768505\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[20]\tvalid_0's multi_logloss: 0.645138\tvalid_0's f1_score: 0.756122\n",
      "[60]\tvalid_0's multi_logloss: 0.546864\tvalid_0's f1_score: 0.786665\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 0.551323\tvalid_0's f1_score: 0.790175\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.568551\tvalid_0's f1_score: 0.775377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.568551\tvalid_0's f1_score: 0.775377\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.544298\tvalid_0's f1_score: 0.78493\n",
      "[10]\tvalid_0's multi_logloss: 0.768576\tvalid_0's f1_score: 0.718479\n",
      "[10]\tvalid_0's multi_logloss: 0.741406\tvalid_0's f1_score: 0.736089\n",
      "[30]\tvalid_0's multi_logloss: 0.601305\tvalid_0's f1_score: 0.768999\n",
      "[10]\tvalid_0's multi_logloss: 0.763927\tvalid_0's f1_score: 0.72719\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[30]\tvalid_0's multi_logloss: 0.60122\tvalid_0's f1_score: 0.76702\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 158142\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.668023\tvalid_0's f1_score: 0.744999\n",
      "[20]\tvalid_0's multi_logloss: 0.666895\tvalid_0's f1_score: 0.743945\n",
      "[60]\tvalid_0's multi_logloss: 0.534482\tvalid_0's f1_score: 0.789254\n",
      "[10]\tvalid_0's multi_logloss: 0.761157\tvalid_0's f1_score: 0.727134\n",
      "[20]\tvalid_0's multi_logloss: 0.643863\tvalid_0's f1_score: 0.753904\n",
      "[40]\tvalid_0's multi_logloss: 0.573678\tvalid_0's f1_score: 0.774923\n",
      "[30]\tvalid_0's multi_logloss: 0.618624\tvalid_0's f1_score: 0.759848\n",
      "[40]\tvalid_0's multi_logloss: 0.577978\tvalid_0's f1_score: 0.774131\n",
      "[10]\tvalid_0's multi_logloss: 0.747286\tvalid_0's f1_score: 0.735323\n",
      "[30]\tvalid_0's multi_logloss: 0.620358\tvalid_0's f1_score: 0.756274\n",
      "[20]\tvalid_0's multi_logloss: 0.66348\tvalid_0's f1_score: 0.744813\n",
      "[40]\tvalid_0's multi_logloss: 0.588439\tvalid_0's f1_score: 0.772969\n",
      "[70]\tvalid_0's multi_logloss: 0.530053\tvalid_0's f1_score: 0.789667\n",
      "[30]\tvalid_0's multi_logloss: 0.598704\tvalid_0's f1_score: 0.763967\n",
      "[50]\tvalid_0's multi_logloss: 0.561135\tvalid_0's f1_score: 0.777951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.561135\tvalid_0's f1_score: 0.777951\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.592799\tvalid_0's f1_score: 0.771074\n",
      "[30]\tvalid_0's multi_logloss: 0.613254\tvalid_0's f1_score: 0.757822\n",
      "[50]\tvalid_0's multi_logloss: 0.563513\tvalid_0's f1_score: 0.780858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.563513\tvalid_0's f1_score: 0.780858\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.648029\tvalid_0's f1_score: 0.750605\n",
      "[50]\tvalid_0's multi_logloss: 0.572798\tvalid_0's f1_score: 0.776917\n",
      "[LightGBM] [Info] Total Bins 158167\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4968\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.575415\tvalid_0's f1_score: 0.776639\n",
      "[40]\tvalid_0's multi_logloss: 0.586323\tvalid_0's f1_score: 0.768505\n",
      "[LightGBM] [Info] Total Bins 157084\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4953\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[80]\tvalid_0's multi_logloss: 0.526105\tvalid_0's f1_score: 0.794277\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.574643\tvalid_0's f1_score: 0.773636\n",
      "[60]\tvalid_0's multi_logloss: 0.561866\tvalid_0's f1_score: 0.780643\n",
      "[60]\tvalid_0's multi_logloss: 0.564569\tvalid_0's f1_score: 0.779937\n",
      "[30]\tvalid_0's multi_logloss: 0.601305\tvalid_0's f1_score: 0.768999\n",
      "[50]\tvalid_0's multi_logloss: 0.568551\tvalid_0's f1_score: 0.775377\n",
      "[10]\tvalid_0's multi_logloss: 0.740224\tvalid_0's f1_score: 0.736096\n",
      "[70]\tvalid_0's multi_logloss: 0.553139\tvalid_0's f1_score: 0.786685\n",
      "[10]\tvalid_0's multi_logloss: 0.741406\tvalid_0's f1_score: 0.736089\n",
      "[70]\tvalid_0's multi_logloss: 0.557925\tvalid_0's f1_score: 0.78288\n",
      "[50]\tvalid_0's multi_logloss: 0.560726\tvalid_0's f1_score: 0.776089\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.560726\tvalid_0's f1_score: 0.776089\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.526858\tvalid_0's f1_score: 0.798052\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_logloss: 0.526105\tvalid_0's f1_score: 0.794277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.557778\tvalid_0's f1_score: 0.780869\n",
      "[80]\tvalid_0's multi_logloss: 0.548611\tvalid_0's f1_score: 0.787066\n",
      "[40]\tvalid_0's multi_logloss: 0.573678\tvalid_0's f1_score: 0.774923\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.552519\tvalid_0's f1_score: 0.784634\n",
      "[20]\tvalid_0's multi_logloss: 0.645138\tvalid_0's f1_score: 0.756122\n",
      "[70]\tvalid_0's multi_logloss: 0.549292\tvalid_0's f1_score: 0.781921\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 0.54989\tvalid_0's f1_score: 0.789608\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.643863\tvalid_0's f1_score: 0.753904\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 0.554478\tvalid_0's f1_score: 0.786479\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 0.769812\tvalid_0's f1_score: 0.715776\n",
      "[10]\tvalid_0's multi_logloss: 0.763428\tvalid_0's f1_score: 0.725637\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[80]\tvalid_0's multi_logloss: 0.543092\tvalid_0's f1_score: 0.782659\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.561135\tvalid_0's f1_score: 0.777951\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.60122\tvalid_0's f1_score: 0.76702\n",
      "[20]\tvalid_0's multi_logloss: 0.669806\tvalid_0's f1_score: 0.741302\n",
      "[20]\tvalid_0's multi_logloss: 0.663973\tvalid_0's f1_score: 0.746888\n",
      "[10]\tvalid_0's multi_logloss: 0.761836\tvalid_0's f1_score: 0.725323\n",
      "[90]\tvalid_0's multi_logloss: 0.538534\tvalid_0's f1_score: 0.788778\n",
      "[30]\tvalid_0's multi_logloss: 0.598704\tvalid_0's f1_score: 0.763967\n",
      "[60]\tvalid_0's multi_logloss: 0.552434\tvalid_0's f1_score: 0.781027\n",
      "[30]\tvalid_0's multi_logloss: 0.619239\tvalid_0's f1_score: 0.758658\n",
      "[30]\tvalid_0's multi_logloss: 0.616743\tvalid_0's f1_score: 0.758588\n",
      "[10]\tvalid_0's multi_logloss: 0.745735\tvalid_0's f1_score: 0.731841\n",
      "[20]\tvalid_0's multi_logloss: 0.663296\tvalid_0's f1_score: 0.743076\n",
      "[100]\tvalid_0's multi_logloss: 0.535993\tvalid_0's f1_score: 0.788528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.535993\tvalid_0's f1_score: 0.788528\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.577978\tvalid_0's f1_score: 0.774131\n",
      "[40]\tvalid_0's multi_logloss: 0.574643\tvalid_0's f1_score: 0.773636\n",
      "[40]\tvalid_0's multi_logloss: 0.591534\tvalid_0's f1_score: 0.76919\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[40]\tvalid_0's multi_logloss: 0.591939\tvalid_0's f1_score: 0.76755\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.61321\tvalid_0's f1_score: 0.761429\n",
      "[70]\tvalid_0's multi_logloss: 0.545039\tvalid_0's f1_score: 0.783118\n",
      "[20]\tvalid_0's multi_logloss: 0.647236\tvalid_0's f1_score: 0.75036\n",
      "[50]\tvalid_0's multi_logloss: 0.57444\tvalid_0's f1_score: 0.77517\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.57444\tvalid_0's f1_score: 0.77517\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.563513\tvalid_0's f1_score: 0.780858\n",
      "[50]\tvalid_0's multi_logloss: 0.577886\tvalid_0's f1_score: 0.772612\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.577886\tvalid_0's f1_score: 0.772612\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.5861\tvalid_0's f1_score: 0.768739\n",
      "[50]\tvalid_0's multi_logloss: 0.560726\tvalid_0's f1_score: 0.776089\n",
      "[10]\tvalid_0's multi_logloss: 0.741678\tvalid_0's f1_score: 0.734865\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.540944\tvalid_0's f1_score: 0.784772\n",
      "[50]\tvalid_0's multi_logloss: 0.569891\tvalid_0's f1_score: 0.77692\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.569891\tvalid_0's f1_score: 0.77692\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.599154\tvalid_0's f1_score: 0.768874\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.554724\tvalid_0's f1_score: 0.787721\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.769812\tvalid_0's f1_score: 0.715776\n",
      "[60]\tvalid_0's multi_logloss: 0.550774\tvalid_0's f1_score: 0.78069\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.644495\tvalid_0's f1_score: 0.751054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.744223\tvalid_0's f1_score: 0.737415\n",
      "[90]\tvalid_0's multi_logloss: 0.537308\tvalid_0's f1_score: 0.787158\n",
      "[40]\tvalid_0's multi_logloss: 0.573752\tvalid_0's f1_score: 0.778618\n",
      "[20]\tvalid_0's multi_logloss: 0.669806\tvalid_0's f1_score: 0.741302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.763428\tvalid_0's f1_score: 0.725637\n",
      "[70]\tvalid_0's multi_logloss: 0.548336\tvalid_0's f1_score: 0.790407\n",
      "[70]\tvalid_0's multi_logloss: 0.543768\tvalid_0's f1_score: 0.784489\n",
      "[30]\tvalid_0's multi_logloss: 0.600671\tvalid_0's f1_score: 0.766909\n",
      "[30]\tvalid_0's multi_logloss: 0.619239\tvalid_0's f1_score: 0.758658\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.536382\tvalid_0's f1_score: 0.78688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.536382\tvalid_0's f1_score: 0.78688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.644884\tvalid_0's f1_score: 0.754453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.663973\tvalid_0's f1_score: 0.746888\n",
      "[50]\tvalid_0's multi_logloss: 0.559271\tvalid_0's f1_score: 0.783111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.559271\tvalid_0's f1_score: 0.783111\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.545045\tvalid_0's f1_score: 0.789965\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 0.548336\tvalid_0's f1_score: 0.790407\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.591534\tvalid_0's f1_score: 0.76919\n",
      "[80]\tvalid_0's multi_logloss: 0.538836\tvalid_0's f1_score: 0.784411\n",
      "[30]\tvalid_0's multi_logloss: 0.616743\tvalid_0's f1_score: 0.758588\n",
      "[LightGBM] [Info] Total Bins 153662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4275\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 153621\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4274\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[40]\tvalid_0's multi_logloss: 0.578588\tvalid_0's f1_score: 0.776053\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 0.541985\tvalid_0's f1_score: 0.786995\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.598026\tvalid_0's f1_score: 0.768655\n",
      "[10]\tvalid_0's multi_logloss: 0.761836\tvalid_0's f1_score: 0.725323\n",
      "[50]\tvalid_0's multi_logloss: 0.57444\tvalid_0's f1_score: 0.77517\n",
      "[40]\tvalid_0's multi_logloss: 0.591939\tvalid_0's f1_score: 0.76755\n",
      "[LightGBM] [Info] Total Bins 152419\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 4242\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.663296\tvalid_0's f1_score: 0.743076\n",
      "[10]\tvalid_0's multi_logloss: 0.745735\tvalid_0's f1_score: 0.731841\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.564006\tvalid_0's f1_score: 0.777358\n",
      "[50]\tvalid_0's multi_logloss: 0.565248\tvalid_0's f1_score: 0.780056\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.565248\tvalid_0's f1_score: 0.780056\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 0.741678\tvalid_0's f1_score: 0.734865\n",
      "[50]\tvalid_0's multi_logloss: 0.577886\tvalid_0's f1_score: 0.772612\n",
      "[40]\tvalid_0's multi_logloss: 0.574228\tvalid_0's f1_score: 0.773873\n",
      "[30]\tvalid_0's multi_logloss: 0.61321\tvalid_0's f1_score: 0.761429\n",
      "[10]\tvalid_0's multi_logloss: 0.744223\tvalid_0's f1_score: 0.737415\n",
      "[70]\tvalid_0's multi_logloss: 0.555824\tvalid_0's f1_score: 0.780038\n",
      "[60]\tvalid_0's multi_logloss: 0.567454\tvalid_0's f1_score: 0.776104\n",
      "[20]\tvalid_0's multi_logloss: 0.647236\tvalid_0's f1_score: 0.75036\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.644495\tvalid_0's f1_score: 0.751054\n",
      "[50]\tvalid_0's multi_logloss: 0.559263\tvalid_0's f1_score: 0.779368\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.559263\tvalid_0's f1_score: 0.779368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.5861\tvalid_0's f1_score: 0.768739\n",
      "[80]\tvalid_0's multi_logloss: 0.549645\tvalid_0's f1_score: 0.785\n",
      "[70]\tvalid_0's multi_logloss: 0.559959\tvalid_0's f1_score: 0.782461\n",
      "[20]\tvalid_0's multi_logloss: 0.644884\tvalid_0's f1_score: 0.754453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.569891\tvalid_0's f1_score: 0.77692\n",
      "[90]\tvalid_0's multi_logloss: 0.545902\tvalid_0's f1_score: 0.785346\n",
      "[80]\tvalid_0's multi_logloss: 0.554821\tvalid_0's f1_score: 0.783086\n",
      "[30]\tvalid_0's multi_logloss: 0.599154\tvalid_0's f1_score: 0.768874\n",
      "[30]\tvalid_0's multi_logloss: 0.600671\tvalid_0's f1_score: 0.766909\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.558483\tvalid_0's f1_score: 0.780849\n",
      "[100]\tvalid_0's multi_logloss: 0.542044\tvalid_0's f1_score: 0.78661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.542044\tvalid_0's f1_score: 0.78661\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.550716\tvalid_0's f1_score: 0.784112\n",
      "[30]\tvalid_0's multi_logloss: 0.598026\tvalid_0's f1_score: 0.768655\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.560619\tvalid_0's f1_score: 0.782503\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.573752\tvalid_0's f1_score: 0.778618\n",
      "[40]\tvalid_0's multi_logloss: 0.578588\tvalid_0's f1_score: 0.776053\n",
      "[100]\tvalid_0's multi_logloss: 0.546908\tvalid_0's f1_score: 0.785138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.546908\tvalid_0's f1_score: 0.785138\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.574228\tvalid_0's f1_score: 0.773873\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.559271\tvalid_0's f1_score: 0.783111\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.565248\tvalid_0's f1_score: 0.780056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.559263\tvalid_0's f1_score: 0.779368\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.549177\tvalid_0's f1_score: 0.787052\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.556988\tvalid_0's f1_score: 0.78486\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.549413\tvalid_0's f1_score: 0.780133\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.550507\tvalid_0's f1_score: 0.788361\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.549885\tvalid_0's f1_score: 0.787032\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.540095\tvalid_0's f1_score: 0.785429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's multi_logloss: 0.551203\tvalid_0's f1_score: 0.787604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.534423\tvalid_0's f1_score: 0.787583\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.531744\tvalid_0's f1_score: 0.787471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 0.533864\tvalid_0's f1_score: 0.789981\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 216198\n",
      "[LightGBM] [Info] Number of data points in the train set: 19887, number of used features: 4996\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.739662\tvalid_0's f1_score: 0.745699\n",
      "[20]\tvalid_0's multi_logloss: 0.640969\tvalid_0's f1_score: 0.758865\n",
      "[30]\tvalid_0's multi_logloss: 0.588864\tvalid_0's f1_score: 0.769757\n",
      "[40]\tvalid_0's multi_logloss: 0.560621\tvalid_0's f1_score: 0.776605\n",
      "[50]\tvalid_0's multi_logloss: 0.543283\tvalid_0's f1_score: 0.783107\n",
      "[60]\tvalid_0's multi_logloss: 0.533526\tvalid_0's f1_score: 0.78882\n",
      "[70]\tvalid_0's multi_logloss: 0.526663\tvalid_0's f1_score: 0.791425\n",
      "[80]\tvalid_0's multi_logloss: 0.521538\tvalid_0's f1_score: 0.792013\n",
      "[90]\tvalid_0's multi_logloss: 0.5194\tvalid_0's f1_score: 0.79414\n",
      "[100]\tvalid_0's multi_logloss: 0.517093\tvalid_0's f1_score: 0.794492\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.517093\tvalid_0's f1_score: 0.794492\n",
      "Best Parameters for LightGBM: {'learning_rate': 0.1, 'max_depth': -1, 'min_data_in_leaf': 10, 'n_estimators': 100, 'num_leaves': 50}\n",
      "Best Cross-Validation Accuracy: 0.8404\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_lgbm = {\n",
    "    \"learning_rate\": [0.01, 0.1],  # Controls the contribution of each tree during boosting\n",
    "    \"n_estimators\": [50, 100],     # Number of boosting stages (trees) to train\n",
    "    \"max_depth\": [-1, 20],         # Maximum depth of the trees (-1 means no limit)\n",
    "    \"num_leaves\": [31, 50],        # Maximum number of leaves per tree (controls tree complexity)\n",
    "    \"min_data_in_leaf\": [10, 20]   # Minimum number of samples required in a leaf node\n",
    "}\n",
    "\n",
    "# Initialize Model\n",
    "lgbm_model = LGBMClassifier(\n",
    "    random_state=42, \n",
    "    force_row_wise=True,    # Optimizes memory usage by processing data row-wise\n",
    "    min_split_gain=0.001    # Minimum gain required to split a node\n",
    "    )\n",
    "\n",
    "# Define callbacks to enhance training\n",
    "callbacks = [\n",
    "    early_stopping(stopping_rounds=10),  # Stops training if no improvement for 10 rounds\n",
    "    log_evaluation(period=10)            # Logs training progress every 10 iterations\n",
    "]\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_lgbm = GridSearchCV(\n",
    "    estimator=lgbm_model,\n",
    "    param_grid=param_grid_lgbm,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer,         # Weighted F1-score as the evaluation metric for hyperparameter search\n",
    "    verbose=True,\n",
    "    n_jobs=-1                                    \n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_lgbm.fit(\n",
    "    X_train_resampled, \n",
    "    y_train_resampled, \n",
    "    eval_set=[(X_test, y_test)],                 # Validation set for monitoring during training\n",
    "    eval_metric=custom_f1_metric_lightgbm,       # Custom F1-score metric for validation\n",
    "    callbacks= callbacks)                        # Callbacks for early stopping and logging\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_lgbm = grid_search_lgbm.best_params_\n",
    "print(f\"Best Parameters for LightGBM: {best_params_lgbm}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_lgbm.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_lgbm = grid_search_lgbm.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_lgbm.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_lgbm, '../models/lightgbm_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1e71b182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>502</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>94</td>\n",
       "      <td>557</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>85</td>\n",
       "      <td>165</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              502       93        82\n",
       "Neutral                94      557       133\n",
       "Positive               85      165      1448"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_lgbm= pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "77120f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_lgbm = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_lgbm = report_lgbm[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_lgbm = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_lgbm = round(weighted_avg_lgbm[\"recall\"], 2)\n",
    "precision_lgbm = round(weighted_avg_lgbm[\"precision\"], 2)\n",
    "f1_score_lgbm = round(weighted_avg_lgbm[\"f1-score\"], 2)\n",
    "f3_score_lgbm = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "003e5fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.79\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.74      0.74       677\n",
      "     Neutral       0.68      0.71      0.70       784\n",
      "    Positive       0.87      0.85      0.86      1698\n",
      "\n",
      "    accuracy                           0.79      3159\n",
      "   macro avg       0.76      0.77      0.77      3159\n",
      "weighted avg       0.80      0.79      0.79      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "classification_report_lgbm = classification_report(y_test, y_pred)\n",
    "print(classification_report_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056fdc0e",
   "metadata": {},
   "source": [
    "# IV. Deep Learning Model Development - LSTM\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab7fc0",
   "metadata": {},
   "source": [
    "## <font color=\"red\">1.  Data Preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aad1b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = process_reviews['Full_review']  # Feature: text reviews\n",
    "y = process_reviews['Sentiment']    # Target: sentiment labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa578b9",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.1.  Encode Sentiment Labels To Integers</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab1d5a2",
   "metadata": {},
   "source": [
    "Converting sentiment labels to numerical data is necessary when training an LSTM model (or any other deep learning model) because neural networks process numerical data, not categorical strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95843349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    8327\n",
       "1    4020\n",
       "0    3444\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode sentiment labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Display the count of each label\n",
    "pd.Series(y_encoded).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e33b9a",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.2. Tokenization</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f03e2a",
   "metadata": {},
   "source": [
    "This step transforms raw text into a structured input format compatible with LSTM models by converting variable-length and complex text into a fixed numerical format.\n",
    "- The Tokenizer class from **Keras** library converts words in the text data (X) into sequences of numerical tokens\n",
    "- By setting num_words=10000, the tokenizer considers only the 10,000 most frequent words, reducing noise and memory usage for large datasets.\n",
    "- Less frequent words are either ignored or replaced with the **oov_token** representing out-of-vocabulary words.\n",
    "- **texts_to_sequences** transforms each text sample into a sequence of integers, preserving the order of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized sequence: [[2, 55, 29, 239, 267, 387, 457, 355, 332, 2002, 82, 305, 267, 47, 197, 15, 245, 1099, 425, 738, 2319, 615, 387, 355, 998, 447, 267, 15, 678, 616, 563, 197, 4334, 966, 82, 678, 616, 457, 355, 237, 678, 616, 76, 957, 893, 267, 15, 1065, 1671, 2410, 6755, 1, 875, 2088, 660, 15, 1020, 894, 3091, 292, 400, 76, 957, 267, 44, 220, 73, 690, 3416, 1367, 82, 4064, 732, 47, 197, 85, 825, 1100, 146, 110, 3092, 2899, 457, 355, 332, 4065, 151, 305, 36, 457, 678, 616, 109, 3185, 9595, 355, 245, 2002, 197, 82, 1128, 1079, 2815, 387, 1024, 1374, 355, 549, 267, 15, 279, 1065, 1224, 465, 447, 710, 163, 128, 1, 1901, 605, 267, 44, 245, 1901, 605, 726, 15, 211, 231, 203, 1273, 292, 373, 76, 957, 28, 32, 305, 732, 47, 286, 1746, 197, 9596, 1, 895, 267, 387, 457, 355, 3093, 4976, 998, 615, 267, 15, 678, 616, 133, 292, 76, 957, 245, 103, 197, 983, 28, 2411, 1714, 3537, 57, 7843, 47, 197, 128, 173, 520, 173, 1128, 678, 616, 601, 292, 400, 76, 957, 443, 267, 44, 1374, 267, 15, 9597, 9598, 605, 726, 197, 3538, 1, 47, 197, 133, 1150, 615, 520, 457, 355, 202, 1480, 364, 9595, 1, 236, 603, 329, 678, 616, 292, 7844, 267, 387, 457, 355, 251, 577, 305, 1902, 2002, 678, 616, 133, 292, 82, 267, 47, 197, 15, 245, 738, 197, 1150, 1099, 425, 1128, 71, 28, 2996, 1714, 3537, 57, 998, 47, 197, 128, 109, 402, 2364], [166, 116, 2089, 267, 15, 110, 80, 1099, 425, 896, 4628, 1847, 15, 166, 906, 2659, 267, 167, 114], [261, 1012, 7, 267, 387, 149, 355, 1079, 7845, 91, 217, 261, 1012, 139, 267, 387, 149, 355, 639, 577, 36, 738, 6756, 616, 2365, 447, 267, 15, 1079, 7845, 28, 3092, 4629, 461, 338, 39, 6757, 85, 387, 3291, 1368, 36, 3539, 197, 109, 3185, 3291, 4066, 2320, 379, 267, 16, 355, 3292, 3186, 2816], [87, 103, 197, 38, 9, 15, 61, 216, 623, 594, 197, 256, 104, 558, 1274, 15, 10, 290, 95, 252, 999, 6, 1286, 3, 88, 4, 1, 5, 76, 34, 4, 11, 111, 200, 6758, 901, 215, 400, 6759, 3540, 4630, 5969, 146, 15, 5, 27, 34, 497, 15, 44, 12, 11, 243, 3700, 70, 15, 1715, 2003, 1, 41, 25, 237, 1080, 23, 8, 15, 20, 29, 159, 396, 225, 92, 317, 3, 20, 138, 88, 127, 1120, 681, 18, 2, 282, 37, 126, 20, 80], [11, 264, 267, 387, 149, 355, 604, 1714, 374, 57, 998, 47, 197, 3094, 7845, 245, 1099, 425, 109, 1397, 1079, 1121, 355, 332, 1066, 76, 616, 220, 300, 292, 73, 1671, 1349, 29, 403, 727, 292, 379, 305, 471, 149, 28, 691, 357, 1555, 2366, 82, 1369, 92, 405, 77, 395, 85, 1746, 434, 18, 217, 387, 355, 103, 1434, 328, 267, 15, 99, 1065, 47, 1, 85, 138, 4631, 1901, 375, 123, 374, 1495, 197]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/tokenizer.joblib']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizes the top 10,000 words and handles out-of-vocab tokens\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")  \n",
    "\n",
    "# Fit the tokenizer on text data\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)  \n",
    "\n",
    "# View a sample of the tokenized sequences\n",
    "print(\"Sample tokenized sequence:\", X_seq[:5])  # Display the first 5 sequences\n",
    "\n",
    "# Save the trained tokenizerd to a file for later use\n",
    "joblib.dump(tokenizer, '../models/tokenizer.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d157641",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.3. Padding and Truncating</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bc74b",
   "metadata": {},
   "source": [
    "Padding and truncating ensures that all sequences in a batch data have the same length for use in deep learning models.\n",
    "\n",
    "A function from the **tensorflow.keras.preprocessing.sequence** module that standardizes sequence lengths by \"padding\" or \"truncating\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b6833212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 padded sequences:\n",
      "Original sequence: [2, 55, 29, 239, 267, 387, 457, 355, 332, 2002, 82, 305, 267, 47, 197, 15, 245, 1099, 425, 738, 2319, 615, 387, 355, 998, 447, 267, 15, 678, 616, 563, 197, 4334, 966, 82, 678, 616, 457, 355, 237, 678, 616, 76, 957, 893, 267, 15, 1065, 1671, 2410, 6755, 1, 875, 2088, 660, 15, 1020, 894, 3091, 292, 400, 76, 957, 267, 44, 220, 73, 690, 3416, 1367, 82, 4064, 732, 47, 197, 85, 825, 1100, 146, 110, 3092, 2899, 457, 355, 332, 4065, 151, 305, 36, 457, 678, 616, 109, 3185, 9595, 355, 245, 2002, 197, 82, 1128, 1079, 2815, 387, 1024, 1374, 355, 549, 267, 15, 279, 1065, 1224, 465, 447, 710, 163, 128, 1, 1901, 605, 267, 44, 245, 1901, 605, 726, 15, 211, 231, 203, 1273, 292, 373, 76, 957, 28, 32, 305, 732, 47, 286, 1746, 197, 9596, 1, 895, 267, 387, 457, 355, 3093, 4976, 998, 615, 267, 15, 678, 616, 133, 292, 76, 957, 245, 103, 197, 983, 28, 2411, 1714, 3537, 57, 7843, 47, 197, 128, 173, 520, 173, 1128, 678, 616, 601, 292, 400, 76, 957, 443, 267, 44, 1374, 267, 15, 9597, 9598, 605, 726, 197, 3538, 1, 47, 197, 133, 1150, 615, 520, 457, 355, 202, 1480, 364, 9595, 1, 236, 603, 329, 678, 616, 292, 7844, 267, 387, 457, 355, 251, 577, 305, 1902, 2002, 678, 616, 133, 292, 82, 267, 47, 197, 15, 245, 738, 197, 1150, 1099, 425, 1128, 71, 28, 2996, 1714, 3537, 57, 998, 47, 197, 128, 109, 402, 2364]\n",
      "Padded/Truncated sequence: [   2   55   29  239  267  387  457  355  332 2002   82  305  267   47\n",
      "  197   15  245 1099  425  738 2319  615  387  355  998  447  267   15\n",
      "  678  616  563  197 4334  966   82  678  616  457  355  237  678  616\n",
      "   76  957  893  267   15 1065 1671 2410 6755    1  875 2088  660   15\n",
      " 1020  894 3091  292  400   76  957  267]\n",
      "--------------------------------------------------\n",
      "Original sequence: [166, 116, 2089, 267, 15, 110, 80, 1099, 425, 896, 4628, 1847, 15, 166, 906, 2659, 267, 167, 114]\n",
      "Padded/Truncated sequence: [ 166  116 2089  267   15  110   80 1099  425  896 4628 1847   15  166\n",
      "  906 2659  267  167  114    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "--------------------------------------------------\n",
      "Original sequence: [261, 1012, 7, 267, 387, 149, 355, 1079, 7845, 91, 217, 261, 1012, 139, 267, 387, 149, 355, 639, 577, 36, 738, 6756, 616, 2365, 447, 267, 15, 1079, 7845, 28, 3092, 4629, 461, 338, 39, 6757, 85, 387, 3291, 1368, 36, 3539, 197, 109, 3185, 3291, 4066, 2320, 379, 267, 16, 355, 3292, 3186, 2816]\n",
      "Padded/Truncated sequence: [ 261 1012    7  267  387  149  355 1079 7845   91  217  261 1012  139\n",
      "  267  387  149  355  639  577   36  738 6756  616 2365  447  267   15\n",
      " 1079 7845   28 3092 4629  461  338   39 6757   85  387 3291 1368   36\n",
      " 3539  197  109 3185 3291 4066 2320  379  267   16  355 3292 3186 2816\n",
      "    0    0    0    0    0    0    0    0]\n",
      "--------------------------------------------------\n",
      "Original sequence: [87, 103, 197, 38, 9, 15, 61, 216, 623, 594, 197, 256, 104, 558, 1274, 15, 10, 290, 95, 252, 999, 6, 1286, 3, 88, 4, 1, 5, 76, 34, 4, 11, 111, 200, 6758, 901, 215, 400, 6759, 3540, 4630, 5969, 146, 15, 5, 27, 34, 497, 15, 44, 12, 11, 243, 3700, 70, 15, 1715, 2003, 1, 41, 25, 237, 1080, 23, 8, 15, 20, 29, 159, 396, 225, 92, 317, 3, 20, 138, 88, 127, 1120, 681, 18, 2, 282, 37, 126, 20, 80]\n",
      "Padded/Truncated sequence: [  87  103  197   38    9   15   61  216  623  594  197  256  104  558\n",
      " 1274   15   10  290   95  252  999    6 1286    3   88    4    1    5\n",
      "   76   34    4   11  111  200 6758  901  215  400 6759 3540 4630 5969\n",
      "  146   15    5   27   34  497   15   44   12   11  243 3700   70   15\n",
      " 1715 2003    1   41   25  237 1080   23]\n",
      "--------------------------------------------------\n",
      "Original sequence: [11, 264, 267, 387, 149, 355, 604, 1714, 374, 57, 998, 47, 197, 3094, 7845, 245, 1099, 425, 109, 1397, 1079, 1121, 355, 332, 1066, 76, 616, 220, 300, 292, 73, 1671, 1349, 29, 403, 727, 292, 379, 305, 471, 149, 28, 691, 357, 1555, 2366, 82, 1369, 92, 405, 77, 395, 85, 1746, 434, 18, 217, 387, 355, 103, 1434, 328, 267, 15, 99, 1065, 47, 1, 85, 138, 4631, 1901, 375, 123, 374, 1495, 197]\n",
      "Padded/Truncated sequence: [  11  264  267  387  149  355  604 1714  374   57  998   47  197 3094\n",
      " 7845  245 1099  425  109 1397 1079 1121  355  332 1066   76  616  220\n",
      "  300  292   73 1671 1349   29  403  727  292  379  305  471  149   28\n",
      "  691  357 1555 2366   82 1369   92  405   77  395   85 1746  434   18\n",
      "  217  387  355  103 1434  328  267   15]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set a fixed length for all sequences\n",
    "max_sequence_length = 64  \n",
    "\n",
    "# Padding adds zeros to the end of shorter sequences, while truncating removes tokens from the end of longer ones.\n",
    "X_padded = pad_sequences(X_seq, maxlen=max_sequence_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "# Display the first 5 padded sequences\n",
    "print(\"First 5 padded sequences:\")\n",
    "for i in range(5):\n",
    "    print(f\"Original sequence: {X_seq[i]}\")\n",
    "    print(f\"Padded/Truncated sequence: {X_padded[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd8878",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.4. Train-Test Split</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "915e563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y_encoded, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0af03f",
   "metadata": {},
   "source": [
    "### <font color=\"red\">1.5. Convert labels to Categorical format</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b081ec",
   "metadata": {},
   "source": [
    "Converts the target labels into a categorical (one-hot encoded) format: binary vectors, which is commonly used in deep learning models, particularly for multi-class classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c33c8a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12632, 64)\n",
      "y_train_one_hot shape: (12632, 3)\n",
      "\n",
      "First 5 one-hot encoded labels (y_train_one_hot):\n",
      "Integer label: 2\n",
      "One-hot vector: [0. 0. 1.]\n",
      "--------------------------------------------------\n",
      "Integer label: 2\n",
      "One-hot vector: [0. 0. 1.]\n",
      "--------------------------------------------------\n",
      "Integer label: 2\n",
      "One-hot vector: [0. 0. 1.]\n",
      "--------------------------------------------------\n",
      "Integer label: 0\n",
      "One-hot vector: [1. 0. 0.]\n",
      "--------------------------------------------------\n",
      "Integer label: 0\n",
      "One-hot vector: [1. 0. 0.]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Converts integer labels into one-hot encoded vectors.\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train_one_hot shape:\", y_train_one_hot.shape)\n",
    "\n",
    "# Display the first 5 one-hot encoded vectors\n",
    "print(\"\\nFirst 5 one-hot encoded labels (y_train_one_hot):\")\n",
    "for i in range(5):\n",
    "    print(f\"Integer label: {y_train[i]}\")\n",
    "    print(f\"One-hot vector: {y_train_one_hot[i]}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72525390",
   "metadata": {},
   "source": [
    "**Shapes After Conversion:**\n",
    "- X_train Shape: (12632, 64): Represents 12,632 samples with 74 features each (e.g., text embeddings or other features).\n",
    "- y_train_one_hot Shape: (12632, 3): Represents 12,632 samples, each with a one-hot encoded vector of length 3 for the three classes (Negative, Neutral, Positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4f3384",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.  Model Development</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2535c",
   "metadata": {},
   "source": [
    "**Model Architecture***\n",
    "This step defines an architecture of the LSTM-based model for multi-class sentiment classification:\n",
    "\n",
    "- Input Layer: Specifies the input shape as a sequence of tokens.\n",
    "- Embedding Layer: Converts words into dense vector representations.\n",
    "- LSTM Layer: Learns sequential dependencies in text.\n",
    "- Dropout: Prevents overfitting.\n",
    "- Dense Layer: Outputs probabilities for 3 sentiment classes (Negative, Neutral, Positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c9b9e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a sequential model\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 64  # Example sequence length\n",
    "model = Sequential([\n",
    "    \n",
    "    # Input Layer to specify the input shape as a sequence of tokens\n",
    "    Input(shape=(sequence_length,)),  # Explicitly define the input shape\n",
    "\n",
    "    # Embedding Layer to convert words into dense vectors\n",
    "    Embedding(input_dim=10000, output_dim=64),\n",
    "    Dropout(0.3), # Prevents overfitting by randomly dropping 30% of connections during training.\n",
    "    \n",
    "    # LSTM Layer for sequential data processing: Processes sequential data and learns dependencies in the sequence.\n",
    "    LSTM(units=64, return_sequences=False),  # return_sequences=False because we don't need outputs at every step\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense Output Layer with softmax for multi-class classification: Produces probabilities for 3 sentiment classes\n",
    "    Dense(units=3, activation='softmax')  # 3 sentiment classes: Negative, Neutral, Positive\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "da2fcb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m640,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">673,219</span> (2.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m673,219\u001b[0m (2.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">673,219</span> (2.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m673,219\u001b[0m (2.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the Model\n",
    "model.compile(\n",
    "    optimizer='adam',  # Adjusts weights to minimize loss efficiently.\n",
    "    loss='categorical_crossentropy',  # Measures the error for multi-class classification.\n",
    "    metrics=['accuracy']   # Evaluation metric\n",
    ")\n",
    "\n",
    "# Model Summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b42b04ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.5060 - loss: 1.0349 - val_accuracy: 0.5497 - val_loss: 0.8981\n",
      "Epoch 2/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5643 - loss: 0.8937 - val_accuracy: 0.6086 - val_loss: 0.8608\n",
      "Epoch 3/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.6399 - loss: 0.8244 - val_accuracy: 0.6233 - val_loss: 0.8637\n",
      "Epoch 4/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.6575 - loss: 0.8257 - val_accuracy: 0.6233 - val_loss: 0.8750\n",
      "Epoch 5/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.6575 - loss: 0.8426 - val_accuracy: 0.6585 - val_loss: 0.8426\n",
      "Epoch 6/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6259 - loss: 0.8964 - val_accuracy: 0.6209 - val_loss: 0.9041\n",
      "Epoch 7/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.6343 - loss: 0.8047 - val_accuracy: 0.6834 - val_loss: 0.7228\n",
      "Epoch 8/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7285 - loss: 0.6497 - val_accuracy: 0.7337 - val_loss: 0.6572\n",
      "Epoch 9/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.7984 - loss: 0.5064 - val_accuracy: 0.7479 - val_loss: 0.6262\n",
      "Epoch 10/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.8426 - loss: 0.4073 - val_accuracy: 0.7622 - val_loss: 0.6308\n",
      "Epoch 11/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.8710 - loss: 0.3572 - val_accuracy: 0.7681 - val_loss: 0.6423\n",
      "Epoch 12/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8905 - loss: 0.3025 - val_accuracy: 0.7689 - val_loss: 0.6488\n",
      "Epoch 13/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.8986 - loss: 0.2845 - val_accuracy: 0.7614 - val_loss: 0.6744\n",
      "Epoch 14/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9169 - loss: 0.2406 - val_accuracy: 0.7507 - val_loss: 0.7152\n",
      "Epoch 15/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9246 - loss: 0.2142 - val_accuracy: 0.7606 - val_loss: 0.7802\n",
      "Epoch 16/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9313 - loss: 0.1931 - val_accuracy: 0.7661 - val_loss: 0.8551\n",
      "Epoch 17/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9385 - loss: 0.1792 - val_accuracy: 0.7630 - val_loss: 0.8877\n",
      "Epoch 18/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9364 - loss: 0.1790 - val_accuracy: 0.7606 - val_loss: 0.9412\n",
      "Epoch 19/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9464 - loss: 0.1583 - val_accuracy: 0.7594 - val_loss: 0.9356\n",
      "Epoch 20/20\n",
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.9461 - loss: 0.1608 - val_accuracy: 0.7444 - val_loss: 1.0163\n"
     ]
    }
   ],
   "source": [
    "# Train the model and save the training history\n",
    "history = model.fit(\n",
    "    X_train, y_train_one_hot,\n",
    "    validation_split=0.2,  # 20% of training data used for validation\n",
    "    epochs=20,            # Adjust epochs based on dataset size\n",
    "    batch_size=32,        # Mini-batch size for gradient updates\n",
    "    verbose=1             # Display training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72643244",
   "metadata": {},
   "source": [
    "Next step is to predict probabilities on test set:\n",
    "- The **predict** method generates probability distributions for each class for every input in the test set (X_test).\n",
    "- The probability predictions are then converted into class labels using **np.argmax** method for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "befdc05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Predicted Probabilities (First 10 Samples):\n",
      "[[0.   0.   1.  ]\n",
      " [0.   0.09 0.91]\n",
      " [0.   0.   1.  ]\n",
      " [0.03 0.88 0.09]\n",
      " [0.72 0.15 0.13]\n",
      " [1.   0.   0.  ]\n",
      " [0.   0.   1.  ]\n",
      " [0.   0.   1.  ]\n",
      " [0.29 0.39 0.31]\n",
      " [0.   1.   0.  ]]\n",
      "\n",
      "Class Predictions (First 10 Samples):\n",
      "[2 2 2 1 0 0 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities on the test set\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Round probabilities to 2 decimal places\n",
    "y_pred_prob_rounded = np.round(y_pred_prob, 2)\n",
    "\n",
    "# Print the predicted probabilities for the first 10 samples\n",
    "print(\"Predicted Probabilities (First 10 Samples):\")\n",
    "print(y_pred_prob_rounded[:10])\n",
    "\n",
    "# Convert probabilities to class predictions\n",
    "y_pred = np.argmax(y_pred_prob_rounded, axis=1)\n",
    "\n",
    "# Print the class predictions for the first 10 samples\n",
    "print(\"\\nClass Predictions (First 10 Samples):\")\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "66867ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file for later use\n",
    "model.save('../models/lstm_model.keras')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e061b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394</td>\n",
       "      <td>170</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>575</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>225</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class    0    1     2\n",
       "Real class                     \n",
       "0                394  170   125\n",
       "1                 49  575   180\n",
       "2                 41  225  1400"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using pandas crosstab\n",
    "cm_lstm = pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "print(\"Confusion Matrix:\")\n",
    "cm_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2fee7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_lstm = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_lstm = report_lstm[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_lstm = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_lstm = round(weighted_avg_lstm[\"recall\"], 2)\n",
    "precision_lstm = round(weighted_avg_lstm[\"precision\"], 2)\n",
    "f1_score_lstm = round(weighted_avg_lstm[\"f1-score\"], 2)\n",
    "f3_score_lstm = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7412bed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67       689\n",
      "           1       0.59      0.72      0.65       804\n",
      "           2       0.82      0.84      0.83      1666\n",
      "\n",
      "    accuracy                           0.75      3159\n",
      "   macro avg       0.74      0.71      0.72      3159\n",
      "weighted avg       0.76      0.75      0.75      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635caa9a",
   "metadata": {},
   "source": [
    "# V. Models Comparison & Selection\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4052e82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table below summarizes the evaluation metrics of all developed models:\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>F3-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Recall  Precision  F1-score  F3-score\n",
       "0             LightGBM      0.79    0.79       0.80      0.79      0.79\n",
       "1          Naive Bayes      0.77    0.77       0.78      0.78      0.77\n",
       "2  Logistic Regression      0.75    0.75       0.75      0.75      0.75\n",
       "3                 LSTM      0.75    0.75       0.76      0.75      0.75\n",
       "4        Random Forest      0.74    0.74       0.75      0.74      0.74\n",
       "5            LinearSVC      0.74    0.74       0.75      0.74      0.74"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame(\n",
    "    {\n",
    "        \"Model\": [\n",
    "            \"Logistic Regression\",\n",
    "            \"Random Forest\",\n",
    "            \"Naive Bayes\",\n",
    "            \"LinearSVC\",\n",
    "            \"LightGBM\",\n",
    "            \"LSTM\"\n",
    "        ],\n",
    "        \"Accuracy\": [\n",
    "            accuracy_log,\n",
    "            accuracy_rf,\n",
    "            accuracy_nb,\n",
    "            accuracy_linear_svc,\n",
    "            accuracy_lgbm,\n",
    "            accuracy_lstm\n",
    "        ],\n",
    "        \"Recall\": [\n",
    "            recall_log,\n",
    "            recall_rf,\n",
    "            recall_nb,\n",
    "            recall_linear_svc,\n",
    "            recall_lgbm,\n",
    "            recall_lstm\n",
    "        ],\n",
    "        \"Precision\": [\n",
    "            precision_log,\n",
    "            precision_rf,\n",
    "            precision_nb,\n",
    "            precision_linear_svc,\n",
    "            precision_lgbm,\n",
    "            precision_lstm\n",
    "        ],\n",
    "        \"F1-score\": [\n",
    "            f1_score_log,\n",
    "            f1_score_rf,\n",
    "            f1_score_nb,\n",
    "            f1_score_linear_svc,\n",
    "            f1_score_lgbm,\n",
    "            f1_score_lstm\n",
    "        ],\n",
    "        \"F3-score\": [\n",
    "            f3_score_log,\n",
    "            f3_score_rf,\n",
    "            f3_score_nb,\n",
    "            f3_score_linear_svc,\n",
    "            f3_score_lgbm,\n",
    "            f3_score_lstm\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"The table below summarizes the evaluation metrics of all developed models:\")\n",
    "print(\"-\"*70)\n",
    "models.sort_values(by=\"F1-score\", ascending=False, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4f9f4",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>Explanation of Using F1-Score and Accuracy for Model Evaluation</u></font>\n",
    "\n",
    "In this project, both F1-score and accuracy are chosen as primary metrics for evaluating and selecting the best-performing model. This decision is based on the following reasons:\n",
    "- **F1-Score:** The dataset has an imbalanced distribution across sentiment classes (Positive, Neutral, Negative). While accuracy could favor the majority class, the F1-score considers both precision (correctly predicted positives) and recall (true positives identified). This balance makes it more suitable for evaluating performance in sentiment analysis tasks where avoiding false positives and minimizing false negatives is critical.\n",
    "- **Accuracy:** Accuracy remains an important overall metric to measure the model's correct predictions across all classes. It provides a straightforward understanding of the model’s general performance.\n",
    "\n",
    "By combining F1-score and accuracy, this evaluation ensures the selected model is both balanced in predicting all sentiment classes and reliable in its overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969046f",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>Model Selection Based on Accuracy & F1-Score</u></font>\n",
    "\n",
    "- LightGBM achieved the highest accuracy (0.79) and F1-score (0.79), making it the best-performing model.\n",
    "- Naive Bayes followed closely with an accuracy of 0.77, showing competitive results for text classification.\n",
    "- LSTM, despite being a deep learning model, performed on par with Logistic Regression (both at 0.75), suggesting that ensemble-based models like LightGBM are more efficient for this task.\n",
    "- Random Forest and LinearSVC showed the lowest performance, with an accuracy of 0.74."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90807389",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>CONCLUSION:</u></font>\n",
    "The LightGBM model will be selected for deployment in the sentiment analysis tool due to its superior performance in terms of F1-score. This model offers the best combination of precision and recall, ensuring accurate and balanced sentiment classification across all classes.\n",
    "\n",
    "If additional interpretability or specific use cases requiring sequential data processing are needed, the Naive Bayes model could serve as a complementary or alternative approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717a8d7",
   "metadata": {},
   "source": [
    "# VI. Hyperparameter-Tuning the Model for Better Results\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c62f4",
   "metadata": {},
   "source": [
    "## <font color=\"red\">1. Optimizing TF-IDF Vectorizer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1eb901d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (15791, 10000)\n",
      "Matrix Sparsity: 99.57%\n",
      "Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced TF-IDF Vectorizer Configuration\n",
    "vectorizer_enhanced = TfidfVectorizer(\n",
    "    max_features=10000,       # Increase features to capture more meaningful patterns\n",
    "    ngram_range=(1, 3),       # Include unigrams, bigrams, and trigrams\n",
    "    min_df=1,                 # Includes terms that appear in at least 1 document.\n",
    "    max_df=0.95,              # Exclude overly common terms (appear in >95% of documents)\n",
    "    sublinear_tf=True,        # Apply logarithmic scaling to term frequency\n",
    "    smooth_idf=True           # Prevent division by zero in IDF calculation\n",
    ")\n",
    "\n",
    "# Generate the TF-IDF feature matrix\n",
    "X_tfidf = vectorizer_enhanced.fit_transform(X)\n",
    "\n",
    "# Analyze TF-IDF matrix\n",
    "print(\"TF-IDF Matrix Shape:\", X_tfidf.shape)\n",
    "print(f\"Matrix Sparsity: {100 * (1 - (X_tfidf.nnz / float(X_tfidf.shape[0] * X_tfidf.shape[1]))):.2f}%\")\n",
    "\n",
    "# Save the trained vectorizer\n",
    "joblib.dump(vectorizer_enhanced, '../models/tfidf_vectorizer_enhanced.joblib')\n",
    "print(\"Vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156595f",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2. Train - Test Split</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3eb46",
   "metadata": {},
   "source": [
    "The dataset is split into training and test sets with 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "228ce0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce918e",
   "metadata": {},
   "source": [
    "## <font color=\"red\">3. Imbalance handling with SMOTE</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dc52807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in training set after SMOTE:\n",
      "Sentiment\n",
      "Positive    6629\n",
      "Negative    6629\n",
      "Neutral     6629\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check class distribution after applying SMOTE\n",
    "print(\"\\nClass distribution in training set after SMOTE:\")\n",
    "print(y_train_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11128306",
   "metadata": {},
   "source": [
    "## <font color=\"red\">4.  Retraining the Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9d335280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03515\tvalid_0's f1_score: 0.703313\n",
      "[10]\tvalid_0's multi_logloss: 1.03528\tvalid_0's f1_score: 0.697925\n",
      "[10]\tvalid_0's multi_logloss: 1.03528\tvalid_0's f1_score: 0.697925\n",
      "[10]\tvalid_0's multi_logloss: 1.03442\tvalid_0's f1_score: 0.701248\n",
      "[10]\tvalid_0's multi_logloss: 1.03442\tvalid_0's f1_score: 0.701248\n",
      "[10]\tvalid_0's multi_logloss: 1.03037\tvalid_0's f1_score: 0.712278\n",
      "[10]\tvalid_0's multi_logloss: 1.03065\tvalid_0's f1_score: 0.717222\n",
      "[10]\tvalid_0's multi_logloss: 1.02923\tvalid_0's f1_score: 0.712757\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.04103\tvalid_0's f1_score: 0.698578\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.04103\tvalid_0's f1_score: 0.698578\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.983349\tvalid_0's f1_score: 0.706706\n",
      "[20]\tvalid_0's multi_logloss: 0.981834\tvalid_0's f1_score: 0.702754\n",
      "[20]\tvalid_0's multi_logloss: 0.981834\tvalid_0's f1_score: 0.702754\n",
      "[30]\tvalid_0's multi_logloss: 0.940062\tvalid_0's f1_score: 0.70846\n",
      "[30]\tvalid_0's multi_logloss: 0.93819\tvalid_0's f1_score: 0.708573\n",
      "[30]\tvalid_0's multi_logloss: 0.93819\tvalid_0's f1_score: 0.708573\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[20]\tvalid_0's multi_logloss: 0.974878\tvalid_0's f1_score: 0.718773\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.974996\tvalid_0's f1_score: 0.718467\n",
      "[20]\tvalid_0's multi_logloss: 0.972846\tvalid_0's f1_score: 0.716282\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.903614\tvalid_0's f1_score: 0.710839\n",
      "[40]\tvalid_0's multi_logloss: 0.901366\tvalid_0's f1_score: 0.713531\n",
      "[40]\tvalid_0's multi_logloss: 0.901366\tvalid_0's f1_score: 0.713531\n",
      "[10]\tvalid_0's multi_logloss: 1.03515\tvalid_0's f1_score: 0.703313\n",
      "[30]\tvalid_0's multi_logloss: 0.928698\tvalid_0's f1_score: 0.720183\n",
      "[30]\tvalid_0's multi_logloss: 0.928424\tvalid_0's f1_score: 0.72133\n",
      "[30]\tvalid_0's multi_logloss: 0.926355\tvalid_0's f1_score: 0.721471\n",
      "[10]\tvalid_0's multi_logloss: 1.03037\tvalid_0's f1_score: 0.712278\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "[50]\tvalid_0's multi_logloss: 0.870117\tvalid_0's f1_score: 0.716549\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.870117\tvalid_0's f1_score: 0.716549\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.870117\tvalid_0's f1_score: 0.716549\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.983349\tvalid_0's f1_score: 0.706706\n",
      "[60]\tvalid_0's multi_logloss: 0.843603\tvalid_0's f1_score: 0.719315\n",
      "[30]\tvalid_0's multi_logloss: 0.940062\tvalid_0's f1_score: 0.70846\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[40]\tvalid_0's multi_logloss: 0.889677\tvalid_0's f1_score: 0.723385\n",
      "[40]\tvalid_0's multi_logloss: 0.889302\tvalid_0's f1_score: 0.724297\n",
      "[40]\tvalid_0's multi_logloss: 0.88737\tvalid_0's f1_score: 0.722482\n",
      "[20]\tvalid_0's multi_logloss: 0.974878\tvalid_0's f1_score: 0.718773\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.821072\tvalid_0's f1_score: 0.722367\n",
      "[40]\tvalid_0's multi_logloss: 0.903614\tvalid_0's f1_score: 0.710839\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 0.904489\tvalid_0's f1_score: 0.724816\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.02923\tvalid_0's f1_score: 0.712757\n",
      "[10]\tvalid_0's multi_logloss: 1.03065\tvalid_0's f1_score: 0.717222\n",
      "[50]\tvalid_0's multi_logloss: 0.856461\tvalid_0's f1_score: 0.726684\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.856461\tvalid_0's f1_score: 0.726684\n",
      "[50]\tvalid_0's multi_logloss: 0.854312\tvalid_0's f1_score: 0.725893\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.854312\tvalid_0's f1_score: 0.725893\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.928698\tvalid_0's f1_score: 0.720183\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.801165\tvalid_0's f1_score: 0.725917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[90]\tvalid_0's multi_logloss: 0.782889\tvalid_0's f1_score: 0.726012\n",
      "[10]\tvalid_0's multi_logloss: 1.03506\tvalid_0's f1_score: 0.699174\n",
      "[60]\tvalid_0's multi_logloss: 0.846035\tvalid_0's f1_score: 0.716172\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.795429\tvalid_0's f1_score: 0.72647\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.972846\tvalid_0's f1_score: 0.716282\n",
      "[20]\tvalid_0's multi_logloss: 0.974996\tvalid_0's f1_score: 0.718467\n",
      "[40]\tvalid_0's multi_logloss: 0.889677\tvalid_0's f1_score: 0.723385\n",
      "[10]\tvalid_0's multi_logloss: 1.03524\tvalid_0's f1_score: 0.70251\n",
      "[10]\tvalid_0's multi_logloss: 1.03454\tvalid_0's f1_score: 0.69685\n",
      "[20]\tvalid_0's multi_logloss: 0.983386\tvalid_0's f1_score: 0.701826\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[70]\tvalid_0's multi_logloss: 0.822911\tvalid_0's f1_score: 0.717482\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 0.904489\tvalid_0's f1_score: 0.724816\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.983363\tvalid_0's f1_score: 0.705114\n",
      "[20]\tvalid_0's multi_logloss: 0.982109\tvalid_0's f1_score: 0.701958\n",
      "[30]\tvalid_0's multi_logloss: 0.940396\tvalid_0's f1_score: 0.702678\n",
      "[30]\tvalid_0's multi_logloss: 0.926355\tvalid_0's f1_score: 0.721471\n",
      "[30]\tvalid_0's multi_logloss: 0.928424\tvalid_0's f1_score: 0.72133\n",
      "[80]\tvalid_0's multi_logloss: 0.802473\tvalid_0's f1_score: 0.720401\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03043\tvalid_0's f1_score: 0.71365\n",
      "[30]\tvalid_0's multi_logloss: 0.938491\tvalid_0's f1_score: 0.703808\n",
      "[30]\tvalid_0's multi_logloss: 0.939889\tvalid_0's f1_score: 0.706299\n",
      "[40]\tvalid_0's multi_logloss: 0.904571\tvalid_0's f1_score: 0.702982\n",
      "[90]\tvalid_0's multi_logloss: 0.783792\tvalid_0's f1_score: 0.72228\n",
      "[40]\tvalid_0's multi_logloss: 0.88737\tvalid_0's f1_score: 0.722482\n",
      "[40]\tvalid_0's multi_logloss: 0.901544\tvalid_0's f1_score: 0.713361\n",
      "[40]\tvalid_0's multi_logloss: 0.903129\tvalid_0's f1_score: 0.707262\n",
      "[40]\tvalid_0's multi_logloss: 0.889302\tvalid_0's f1_score: 0.724297\n",
      "[10]\tvalid_0's multi_logloss: 1.0296\tvalid_0's f1_score: 0.712702\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[100]\tvalid_0's multi_logloss: 0.76729\tvalid_0's f1_score: 0.723742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.76729\tvalid_0's f1_score: 0.723742\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.97528\tvalid_0's f1_score: 0.71427\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 1.0422\tvalid_0's f1_score: 0.714897\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.854312\tvalid_0's f1_score: 0.725893\n",
      "[50]\tvalid_0's multi_logloss: 0.856461\tvalid_0's f1_score: 0.726684\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.929293\tvalid_0's f1_score: 0.7143\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[10]\tvalid_0's multi_logloss: 1.03506\tvalid_0's f1_score: 0.699174\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03102\tvalid_0's f1_score: 0.711573\n",
      "[10]\tvalid_0's multi_logloss: 1.03454\tvalid_0's f1_score: 0.69685\n",
      "[10]\tvalid_0's multi_logloss: 1.03524\tvalid_0's f1_score: 0.70251\n",
      "[60]\tvalid_0's multi_logloss: 0.826136\tvalid_0's f1_score: 0.729439\n",
      "[60]\tvalid_0's multi_logloss: 0.82821\tvalid_0's f1_score: 0.729377\n",
      "[20]\tvalid_0's multi_logloss: 0.983386\tvalid_0's f1_score: 0.701826\n",
      "[40]\tvalid_0's multi_logloss: 0.890983\tvalid_0's f1_score: 0.723183\n",
      "[20]\tvalid_0's multi_logloss: 0.982109\tvalid_0's f1_score: 0.701958\n",
      "[20]\tvalid_0's multi_logloss: 0.983363\tvalid_0's f1_score: 0.705114\n",
      "[10]\tvalid_0's multi_logloss: 1.03043\tvalid_0's f1_score: 0.71365\n",
      "[20]\tvalid_0's multi_logloss: 0.975379\tvalid_0's f1_score: 0.715025\n",
      "[30]\tvalid_0's multi_logloss: 0.940396\tvalid_0's f1_score: 0.702678\n",
      "[30]\tvalid_0's multi_logloss: 0.938491\tvalid_0's f1_score: 0.703808\n",
      "[30]\tvalid_0's multi_logloss: 0.939889\tvalid_0's f1_score: 0.706299\n",
      "[70]\tvalid_0's multi_logloss: 0.801939\tvalid_0's f1_score: 0.732144\n",
      "[70]\tvalid_0's multi_logloss: 0.803641\tvalid_0's f1_score: 0.730929\n",
      "[40]\tvalid_0's multi_logloss: 0.904571\tvalid_0's f1_score: 0.702982\n",
      "[50]\tvalid_0's multi_logloss: 0.858685\tvalid_0's f1_score: 0.722209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.858685\tvalid_0's f1_score: 0.722209\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.97528\tvalid_0's f1_score: 0.71427\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.818006\tvalid_0's f1_score: 0.732058\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.901544\tvalid_0's f1_score: 0.713361\n",
      "[40]\tvalid_0's multi_logloss: 0.903129\tvalid_0's f1_score: 0.707262\n",
      "[30]\tvalid_0's multi_logloss: 0.929053\tvalid_0's f1_score: 0.721873\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[80]\tvalid_0's multi_logloss: 0.781339\tvalid_0's f1_score: 0.733521\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "[30]\tvalid_0's multi_logloss: 0.929293\tvalid_0's f1_score: 0.7143\n",
      "[60]\tvalid_0's multi_logloss: 0.847913\tvalid_0's f1_score: 0.715373\n",
      "[40]\tvalid_0's multi_logloss: 0.889842\tvalid_0's f1_score: 0.721566\n",
      "[10]\tvalid_0's multi_logloss: 1.0296\tvalid_0's f1_score: 0.712702\n",
      "[60]\tvalid_0's multi_logloss: 0.843706\tvalid_0's f1_score: 0.718859\n",
      "[60]\tvalid_0's multi_logloss: 0.845376\tvalid_0's f1_score: 0.713493\n",
      "[10]\tvalid_0's multi_logloss: 1.03102\tvalid_0's f1_score: 0.711573\n",
      "[90]\tvalid_0's multi_logloss: 0.763155\tvalid_0's f1_score: 0.736416\n",
      "[70]\tvalid_0's multi_logloss: 0.825403\tvalid_0's f1_score: 0.718324\n",
      "[40]\tvalid_0's multi_logloss: 0.890983\tvalid_0's f1_score: 0.723183\n",
      "[70]\tvalid_0's multi_logloss: 0.822139\tvalid_0's f1_score: 0.714936\n",
      "[70]\tvalid_0's multi_logloss: 0.821114\tvalid_0's f1_score: 0.724185\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 1.0422\tvalid_0's f1_score: 0.714897\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.856866\tvalid_0's f1_score: 0.723803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.856866\tvalid_0's f1_score: 0.723803\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[80]\tvalid_0's multi_logloss: 0.80533\tvalid_0's f1_score: 0.718203\n",
      "[20]\tvalid_0's multi_logloss: 0.975379\tvalid_0's f1_score: 0.715025\n",
      "[100]\tvalid_0's multi_logloss: 0.74693\tvalid_0's f1_score: 0.738887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.74693\tvalid_0's f1_score: 0.738887\n",
      "[80]\tvalid_0's multi_logloss: 0.801552\tvalid_0's f1_score: 0.716955\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[80]\tvalid_0's multi_logloss: 0.801171\tvalid_0's f1_score: 0.726777\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.858685\tvalid_0's f1_score: 0.722209\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[90]\tvalid_0's multi_logloss: 0.78719\tvalid_0's f1_score: 0.72023\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[90]\tvalid_0's multi_logloss: 0.782869\tvalid_0's f1_score: 0.719596\n",
      "[90]\tvalid_0's multi_logloss: 0.78309\tvalid_0's f1_score: 0.725449\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_logloss: 0.801171\tvalid_0's f1_score: 0.726777\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 0.874174\tvalid_0's f1_score: 0.724462\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[30]\tvalid_0's multi_logloss: 0.929053\tvalid_0's f1_score: 0.721873\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03528\tvalid_0's f1_score: 0.697925\n",
      "[100]\tvalid_0's multi_logloss: 0.771752\tvalid_0's f1_score: 0.72408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.771752\tvalid_0's f1_score: 0.72408\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 1.03442\tvalid_0's f1_score: 0.701248\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[100]\tvalid_0's multi_logloss: 0.766197\tvalid_0's f1_score: 0.724181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.766197\tvalid_0's f1_score: 0.724181\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[10]\tvalid_0's multi_logloss: 1.03515\tvalid_0's f1_score: 0.703313\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.04103\tvalid_0's f1_score: 0.698578\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[20]\tvalid_0's multi_logloss: 0.981834\tvalid_0's f1_score: 0.702754\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.889842\tvalid_0's f1_score: 0.721566\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[20]\tvalid_0's multi_logloss: 0.983349\tvalid_0's f1_score: 0.706706\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.93819\tvalid_0's f1_score: 0.708573\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03046\tvalid_0's f1_score: 0.712813\n",
      "[10]\tvalid_0's multi_logloss: 1.02922\tvalid_0's f1_score: 0.712939\n",
      "[10]\tvalid_0's multi_logloss: 1.03528\tvalid_0's f1_score: 0.697925\n",
      "[10]\tvalid_0's multi_logloss: 1.03075\tvalid_0's f1_score: 0.716906\n",
      "[30]\tvalid_0's multi_logloss: 0.940062\tvalid_0's f1_score: 0.70846\n",
      "[50]\tvalid_0's multi_logloss: 0.856866\tvalid_0's f1_score: 0.723803\n",
      "[40]\tvalid_0's multi_logloss: 0.901368\tvalid_0's f1_score: 0.713531\n",
      "[10]\tvalid_0's multi_logloss: 1.03442\tvalid_0's f1_score: 0.701248\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.0553\tvalid_0's f1_score: 0.714247\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.04103\tvalid_0's f1_score: 0.698578\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.903614\tvalid_0's f1_score: 0.710839\n",
      "[20]\tvalid_0's multi_logloss: 0.97506\tvalid_0's f1_score: 0.716672\n",
      "[50]\tvalid_0's multi_logloss: 0.870205\tvalid_0's f1_score: 0.717136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.870205\tvalid_0's f1_score: 0.717136\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.981834\tvalid_0's f1_score: 0.702754\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.975036\tvalid_0's f1_score: 0.721672\n",
      "[60]\tvalid_0's multi_logloss: 0.828617\tvalid_0's f1_score: 0.728214\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.93819\tvalid_0's f1_score: 0.708573\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[30]\tvalid_0's multi_logloss: 0.928791\tvalid_0's f1_score: 0.721781\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03515\tvalid_0's f1_score: 0.703313\n",
      "[30]\tvalid_0's multi_logloss: 0.928634\tvalid_0's f1_score: 0.722485\n",
      "[70]\tvalid_0's multi_logloss: 0.804223\tvalid_0's f1_score: 0.727299\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[40]\tvalid_0's multi_logloss: 0.901368\tvalid_0's f1_score: 0.713531\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03046\tvalid_0's f1_score: 0.712813\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's multi_logloss: 0.820893\tvalid_0's f1_score: 0.729061\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.983349\tvalid_0's f1_score: 0.706706\n",
      "[10]\tvalid_0's multi_logloss: 1.02922\tvalid_0's f1_score: 0.712939\n",
      "[40]\tvalid_0's multi_logloss: 0.889946\tvalid_0's f1_score: 0.723093\n",
      "[50]\tvalid_0's multi_logloss: 0.870205\tvalid_0's f1_score: 0.717136\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.889635\tvalid_0's f1_score: 0.725382\n",
      "[10]\tvalid_0's multi_logloss: 1.03075\tvalid_0's f1_score: 0.716906\n",
      "[30]\tvalid_0's multi_logloss: 0.940062\tvalid_0's f1_score: 0.70846\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 1.0553\tvalid_0's f1_score: 0.714247\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.97506\tvalid_0's f1_score: 0.716672\n",
      "[60]\tvalid_0's multi_logloss: 0.843531\tvalid_0's f1_score: 0.720196\n",
      "[10]\tvalid_0's multi_logloss: 1.03506\tvalid_0's f1_score: 0.699174\n",
      "[50]\tvalid_0's multi_logloss: 0.857097\tvalid_0's f1_score: 0.725795\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.857097\tvalid_0's f1_score: 0.725795\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.903614\tvalid_0's f1_score: 0.710839\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.821045\tvalid_0's f1_score: 0.7232\n",
      "[50]\tvalid_0's multi_logloss: 0.856503\tvalid_0's f1_score: 0.72705\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.856503\tvalid_0's f1_score: 0.72705\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.975036\tvalid_0's f1_score: 0.721672\n",
      "[20]\tvalid_0's multi_logloss: 0.983386\tvalid_0's f1_score: 0.701826\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 1.03454\tvalid_0's f1_score: 0.69685\n",
      "[30]\tvalid_0's multi_logloss: 0.928791\tvalid_0's f1_score: 0.721781\n",
      "[50]\tvalid_0's multi_logloss: 0.872506\tvalid_0's f1_score: 0.712466\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.800998\tvalid_0's f1_score: 0.727399\n",
      "[30]\tvalid_0's multi_logloss: 0.940396\tvalid_0's f1_score: 0.702678\n",
      "[10]\tvalid_0's multi_logloss: 1.03524\tvalid_0's f1_score: 0.70251\n",
      "[20]\tvalid_0's multi_logloss: 0.982109\tvalid_0's f1_score: 0.701958\n",
      "[60]\tvalid_0's multi_logloss: 0.846035\tvalid_0's f1_score: 0.716172\n",
      "[30]\tvalid_0's multi_logloss: 0.928634\tvalid_0's f1_score: 0.722485\n",
      "[90]\tvalid_0's multi_logloss: 0.782902\tvalid_0's f1_score: 0.726529\n",
      "[40]\tvalid_0's multi_logloss: 0.889946\tvalid_0's f1_score: 0.723093\n",
      "[40]\tvalid_0's multi_logloss: 0.904571\tvalid_0's f1_score: 0.702982\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's multi_logloss: 0.797208\tvalid_0's f1_score: 0.727711\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.983363\tvalid_0's f1_score: 0.705114\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.03045\tvalid_0's f1_score: 0.712721\n",
      "[30]\tvalid_0's multi_logloss: 0.938491\tvalid_0's f1_score: 0.703808\n",
      "[70]\tvalid_0's multi_logloss: 0.822911\tvalid_0's f1_score: 0.717482\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.939889\tvalid_0's f1_score: 0.706299\n",
      "[40]\tvalid_0's multi_logloss: 0.889635\tvalid_0's f1_score: 0.725382\n",
      "[40]\tvalid_0's multi_logloss: 0.901544\tvalid_0's f1_score: 0.713361\n",
      "[80]\tvalid_0's multi_logloss: 0.802473\tvalid_0's f1_score: 0.720401\n",
      "[50]\tvalid_0's multi_logloss: 0.857097\tvalid_0's f1_score: 0.725795\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[20]\tvalid_0's multi_logloss: 0.975274\tvalid_0's f1_score: 0.715537\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.903129\tvalid_0's f1_score: 0.707262\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.02974\tvalid_0's f1_score: 0.713801\n",
      "[90]\tvalid_0's multi_logloss: 0.783794\tvalid_0's f1_score: 0.7219\n",
      "[50]\tvalid_0's multi_logloss: 0.856503\tvalid_0's f1_score: 0.72705\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.829003\tvalid_0's f1_score: 0.727999\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.929298\tvalid_0's f1_score: 0.715479\n",
      "[10]\tvalid_0's multi_logloss: 1.03089\tvalid_0's f1_score: 0.711504\n",
      "[100]\tvalid_0's multi_logloss: 0.76732\tvalid_0's f1_score: 0.724979\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.76732\tvalid_0's f1_score: 0.724979\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 0.842487\tvalid_0's f1_score: 0.728509\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.973795\tvalid_0's f1_score: 0.711765\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.03506\tvalid_0's f1_score: 0.699174\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[60]\tvalid_0's multi_logloss: 0.828018\tvalid_0's f1_score: 0.728671\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.00043\tvalid_0's f1_score: 0.715415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 1.03454\tvalid_0's f1_score: 0.69685\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.890897\tvalid_0's f1_score: 0.721351\n",
      "[20]\tvalid_0's multi_logloss: 0.975383\tvalid_0's f1_score: 0.716287\n",
      "[20]\tvalid_0's multi_logloss: 0.983386\tvalid_0's f1_score: 0.701826\n",
      "[10]\tvalid_0's multi_logloss: 1.03524\tvalid_0's f1_score: 0.70251\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.982109\tvalid_0's f1_score: 0.701958\n",
      "[70]\tvalid_0's multi_logloss: 0.803388\tvalid_0's f1_score: 0.733028\n",
      "[30]\tvalid_0's multi_logloss: 0.940396\tvalid_0's f1_score: 0.702678\n",
      "[10]\tvalid_0's multi_logloss: 1.03045\tvalid_0's f1_score: 0.712721\n",
      "[20]\tvalid_0's multi_logloss: 0.983363\tvalid_0's f1_score: 0.705114\n",
      "[50]\tvalid_0's multi_logloss: 0.858585\tvalid_0's f1_score: 0.722918\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.858585\tvalid_0's f1_score: 0.722918\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.928985\tvalid_0's f1_score: 0.721377\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.938491\tvalid_0's f1_score: 0.703808\n",
      "[40]\tvalid_0's multi_logloss: 0.904571\tvalid_0's f1_score: 0.702982\n",
      "[10]\tvalid_0's multi_logloss: 1.02974\tvalid_0's f1_score: 0.713801\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[30]\tvalid_0's multi_logloss: 0.939889\tvalid_0's f1_score: 0.706299\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.782196\tvalid_0's f1_score: 0.734042\n",
      "[40]\tvalid_0's multi_logloss: 0.901544\tvalid_0's f1_score: 0.713361\n",
      "[20]\tvalid_0's multi_logloss: 0.975274\tvalid_0's f1_score: 0.715537\n",
      "[40]\tvalid_0's multi_logloss: 0.889838\tvalid_0's f1_score: 0.722894\n",
      "[50]\tvalid_0's multi_logloss: 0.874085\tvalid_0's f1_score: 0.71029\n",
      "[40]\tvalid_0's multi_logloss: 0.903129\tvalid_0's f1_score: 0.707262\n",
      "[20]\tvalid_0's multi_logloss: 0.973795\tvalid_0's f1_score: 0.711765\n",
      "[10]\tvalid_0's multi_logloss: 1.03089\tvalid_0's f1_score: 0.711504\n",
      "[50]\tvalid_0's multi_logloss: 0.870233\tvalid_0's f1_score: 0.716289\n",
      "[60]\tvalid_0's multi_logloss: 0.847913\tvalid_0's f1_score: 0.715373\n",
      "[90]\tvalid_0's multi_logloss: 0.763447\tvalid_0's f1_score: 0.734377\n",
      "[50]\tvalid_0's multi_logloss: 0.871965\tvalid_0's f1_score: 0.710504\n",
      "[30]\tvalid_0's multi_logloss: 0.929298\tvalid_0's f1_score: 0.715479\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 1.00043\tvalid_0's f1_score: 0.715415\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.856977\tvalid_0's f1_score: 0.725054\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.856977\tvalid_0's f1_score: 0.725054\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[60]\tvalid_0's multi_logloss: 0.843731\tvalid_0's f1_score: 0.718859\n",
      "[70]\tvalid_0's multi_logloss: 0.825403\tvalid_0's f1_score: 0.718324\n",
      "[60]\tvalid_0's multi_logloss: 0.845376\tvalid_0's f1_score: 0.713493\n",
      "[20]\tvalid_0's multi_logloss: 0.975383\tvalid_0's f1_score: 0.716287\n",
      "[100]\tvalid_0's multi_logloss: 0.746248\tvalid_0's f1_score: 0.734065\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.746248\tvalid_0's f1_score: 0.734065\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[70]\tvalid_0's multi_logloss: 0.821103\tvalid_0's f1_score: 0.722529\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[40]\tvalid_0's multi_logloss: 0.890897\tvalid_0's f1_score: 0.721351\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.805359\tvalid_0's f1_score: 0.718499\n",
      "[70]\tvalid_0's multi_logloss: 0.822139\tvalid_0's f1_score: 0.714936\n",
      "[80]\tvalid_0's multi_logloss: 0.800952\tvalid_0's f1_score: 0.725829\n",
      "[10]\tvalid_0's multi_logloss: 0.766377\tvalid_0's f1_score: 0.724127\n",
      "[30]\tvalid_0's multi_logloss: 0.928985\tvalid_0's f1_score: 0.721377\n",
      "[10]\tvalid_0's multi_logloss: 0.764149\tvalid_0's f1_score: 0.724628\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[90]\tvalid_0's multi_logloss: 0.787345\tvalid_0's f1_score: 0.720556\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[80]\tvalid_0's multi_logloss: 0.801646\tvalid_0's f1_score: 0.717832\n",
      "[50]\tvalid_0's multi_logloss: 0.858585\tvalid_0's f1_score: 0.722918\n",
      "[90]\tvalid_0's multi_logloss: 0.782865\tvalid_0's f1_score: 0.725962\n",
      "[20]\tvalid_0's multi_logloss: 0.666168\tvalid_0's f1_score: 0.749673\n",
      "[20]\tvalid_0's multi_logloss: 0.66756\tvalid_0's f1_score: 0.739288\n",
      "[100]\tvalid_0's multi_logloss: 0.771848\tvalid_0's f1_score: 0.72319\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.771848\tvalid_0's f1_score: 0.72319\n",
      "[10]\tvalid_0's multi_logloss: 0.76063\tvalid_0's f1_score: 0.726916\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[90]\tvalid_0's multi_logloss: 0.783114\tvalid_0's f1_score: 0.720537\n",
      "[40]\tvalid_0's multi_logloss: 0.889838\tvalid_0's f1_score: 0.722894\n",
      "[100]\tvalid_0's multi_logloss: 0.767007\tvalid_0's f1_score: 0.726592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.767007\tvalid_0's f1_score: 0.726592\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.61305\tvalid_0's f1_score: 0.76458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.619796\tvalid_0's f1_score: 0.752059\n",
      "[60]\tvalid_0's multi_logloss: 0.830724\tvalid_0's f1_score: 0.726221\n",
      "[20]\tvalid_0's multi_logloss: 0.66148\tvalid_0's f1_score: 0.748548\n",
      "[100]\tvalid_0's multi_logloss: 0.766345\tvalid_0's f1_score: 0.72359\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.766345\tvalid_0's f1_score: 0.72359\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.583144\tvalid_0's f1_score: 0.772859\n",
      "[40]\tvalid_0's multi_logloss: 0.593214\tvalid_0's f1_score: 0.764602\n",
      "[50]\tvalid_0's multi_logloss: 0.856977\tvalid_0's f1_score: 0.725054\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.609878\tvalid_0's f1_score: 0.764105\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[70]\tvalid_0's multi_logloss: 0.806758\tvalid_0's f1_score: 0.725701\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.564989\tvalid_0's f1_score: 0.780127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.564989\tvalid_0's f1_score: 0.780127\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.74443\tvalid_0's f1_score: 0.733159\n",
      "[50]\tvalid_0's multi_logloss: 0.577041\tvalid_0's f1_score: 0.770964\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.577041\tvalid_0's f1_score: 0.770964\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.580963\tvalid_0's f1_score: 0.774323\n",
      "[60]\tvalid_0's multi_logloss: 0.828683\tvalid_0's f1_score: 0.728429\n",
      "[10]\tvalid_0's multi_logloss: 0.742325\tvalid_0's f1_score: 0.736619\n",
      "[50]\tvalid_0's multi_logloss: 0.564138\tvalid_0's f1_score: 0.778723\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.564138\tvalid_0's f1_score: 0.778723\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[80]\tvalid_0's multi_logloss: 0.785932\tvalid_0's f1_score: 0.729551\n",
      "[10]\tvalid_0's multi_logloss: 0.743007\tvalid_0's f1_score: 0.7341\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.64369\tvalid_0's f1_score: 0.754032\n",
      "[70]\tvalid_0's multi_logloss: 0.804304\tvalid_0's f1_score: 0.730249\n",
      "[10]\tvalid_0's multi_logloss: 0.766377\tvalid_0's f1_score: 0.724127\n",
      "[20]\tvalid_0's multi_logloss: 0.647336\tvalid_0's f1_score: 0.748805\n",
      "[10]\tvalid_0's multi_logloss: 0.764149\tvalid_0's f1_score: 0.724628\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[90]\tvalid_0's multi_logloss: 0.76755\tvalid_0's f1_score: 0.733393\n",
      "[20]\tvalid_0's multi_logloss: 0.642621\tvalid_0's f1_score: 0.755522\n",
      "[20]\tvalid_0's multi_logloss: 0.666168\tvalid_0's f1_score: 0.749673\n",
      "[30]\tvalid_0's multi_logloss: 0.591716\tvalid_0's f1_score: 0.767117\n",
      "[20]\tvalid_0's multi_logloss: 0.66756\tvalid_0's f1_score: 0.739288\n",
      "[10]\tvalid_0's multi_logloss: 0.76063\tvalid_0's f1_score: 0.726916\n",
      "[80]\tvalid_0's multi_logloss: 0.783149\tvalid_0's f1_score: 0.730535\n",
      "[30]\tvalid_0's multi_logloss: 0.599107\tvalid_0's f1_score: 0.764743\n",
      "[30]\tvalid_0's multi_logloss: 0.61305\tvalid_0's f1_score: 0.76458\n",
      "[100]\tvalid_0's multi_logloss: 0.750994\tvalid_0's f1_score: 0.736341\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.750994\tvalid_0's f1_score: 0.736341\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.619796\tvalid_0's f1_score: 0.752059\n",
      "[30]\tvalid_0's multi_logloss: 0.593776\tvalid_0's f1_score: 0.769112\n",
      "[20]\tvalid_0's multi_logloss: 0.66148\tvalid_0's f1_score: 0.748548\n",
      "[40]\tvalid_0's multi_logloss: 0.563676\tvalid_0's f1_score: 0.777466\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.785136\tvalid_0's f1_score: 0.730625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.583144\tvalid_0's f1_score: 0.772859\n",
      "[40]\tvalid_0's multi_logloss: 0.593214\tvalid_0's f1_score: 0.764602\n",
      "[30]\tvalid_0's multi_logloss: 0.609878\tvalid_0's f1_score: 0.764105\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.573117\tvalid_0's f1_score: 0.775583\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.56566\tvalid_0's f1_score: 0.780584\n",
      "[50]\tvalid_0's multi_logloss: 0.564989\tvalid_0's f1_score: 0.780127\n",
      "[50]\tvalid_0's multi_logloss: 0.577041\tvalid_0's f1_score: 0.770964\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.54849\tvalid_0's f1_score: 0.784409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.54849\tvalid_0's f1_score: 0.784409\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.580963\tvalid_0's f1_score: 0.774323\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.559952\tvalid_0's f1_score: 0.779655\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.559952\tvalid_0's f1_score: 0.779655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.74443\tvalid_0's f1_score: 0.733159\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.55256\tvalid_0's f1_score: 0.781962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.567197\tvalid_0's f1_score: 0.778189\n",
      "[50]\tvalid_0's multi_logloss: 0.564138\tvalid_0's f1_score: 0.778723\n",
      "[50]\tvalid_0's multi_logloss: 0.550941\tvalid_0's f1_score: 0.78466\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.550941\tvalid_0's f1_score: 0.78466\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.742325\tvalid_0's f1_score: 0.736619\n",
      "[70]\tvalid_0's multi_logloss: 0.54446\tvalid_0's f1_score: 0.78248\n",
      "[70]\tvalid_0's multi_logloss: 0.5603\tvalid_0's f1_score: 0.781364\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[60]\tvalid_0's multi_logloss: 0.552284\tvalid_0's f1_score: 0.784064\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.64369\tvalid_0's f1_score: 0.754032\n",
      "[10]\tvalid_0's multi_logloss: 0.766546\tvalid_0's f1_score: 0.719032\n",
      "[80]\tvalid_0's multi_logloss: 0.539266\tvalid_0's f1_score: 0.787531\n",
      "[10]\tvalid_0's multi_logloss: 0.743007\tvalid_0's f1_score: 0.7341\n",
      "[80]\tvalid_0's multi_logloss: 0.554234\tvalid_0's f1_score: 0.783145\n",
      "[10]\tvalid_0's multi_logloss: 0.762413\tvalid_0's f1_score: 0.726684\n",
      "[70]\tvalid_0's multi_logloss: 0.544683\tvalid_0's f1_score: 0.789205\n",
      "[20]\tvalid_0's multi_logloss: 0.647336\tvalid_0's f1_score: 0.748805\n",
      "[20]\tvalid_0's multi_logloss: 0.665618\tvalid_0's f1_score: 0.750691\n",
      "[90]\tvalid_0's multi_logloss: 0.535458\tvalid_0's f1_score: 0.788073\n",
      "[90]\tvalid_0's multi_logloss: 0.550603\tvalid_0's f1_score: 0.787772\n",
      "[30]\tvalid_0's multi_logloss: 0.591716\tvalid_0's f1_score: 0.767117\n",
      "[20]\tvalid_0's multi_logloss: 0.666042\tvalid_0's f1_score: 0.744217\n",
      "[80]\tvalid_0's multi_logloss: 0.538112\tvalid_0's f1_score: 0.789017\n",
      "[30]\tvalid_0's multi_logloss: 0.613441\tvalid_0's f1_score: 0.766924\n",
      "[20]\tvalid_0's multi_logloss: 0.642621\tvalid_0's f1_score: 0.755522\n",
      "[100]\tvalid_0's multi_logloss: 0.532634\tvalid_0's f1_score: 0.789525\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.532634\tvalid_0's f1_score: 0.789525\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.599107\tvalid_0's f1_score: 0.764743\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[100]\tvalid_0's multi_logloss: 0.547124\tvalid_0's f1_score: 0.790291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.547124\tvalid_0's f1_score: 0.790291\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[30]\tvalid_0's multi_logloss: 0.617785\tvalid_0's f1_score: 0.756904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.533551\tvalid_0's f1_score: 0.790014\n",
      "[40]\tvalid_0's multi_logloss: 0.581552\tvalid_0's f1_score: 0.772724\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[40]\tvalid_0's multi_logloss: 0.563676\tvalid_0's f1_score: 0.777466\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.592003\tvalid_0's f1_score: 0.766836\n",
      "[100]\tvalid_0's multi_logloss: 0.530965\tvalid_0's f1_score: 0.789045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.530965\tvalid_0's f1_score: 0.789045\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.593776\tvalid_0's f1_score: 0.769112\n",
      "[40]\tvalid_0's multi_logloss: 0.573117\tvalid_0's f1_score: 0.775583\n",
      "[50]\tvalid_0's multi_logloss: 0.564468\tvalid_0's f1_score: 0.77772\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.564468\tvalid_0's f1_score: 0.77772\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[10]\tvalid_0's multi_logloss: 0.764153\tvalid_0's f1_score: 0.721392\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.574071\tvalid_0's f1_score: 0.775712\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.574071\tvalid_0's f1_score: 0.775712\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.54849\tvalid_0's f1_score: 0.784409\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[10]\tvalid_0's multi_logloss: 0.747045\tvalid_0's f1_score: 0.73702\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[20]\tvalid_0's multi_logloss: 0.663966\tvalid_0's f1_score: 0.743662\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.56566\tvalid_0's f1_score: 0.780584\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.559952\tvalid_0's f1_score: 0.779655\n",
      "[10]\tvalid_0's multi_logloss: 0.741735\tvalid_0's f1_score: 0.730906\n",
      "[30]\tvalid_0's multi_logloss: 0.610941\tvalid_0's f1_score: 0.761766\n",
      "[10]\tvalid_0's multi_logloss: 0.766546\tvalid_0's f1_score: 0.719032\n",
      "[60]\tvalid_0's multi_logloss: 0.539052\tvalid_0's f1_score: 0.787792\n",
      "[10]\tvalid_0's multi_logloss: 0.743107\tvalid_0's f1_score: 0.730792\n",
      "[20]\tvalid_0's multi_logloss: 0.646182\tvalid_0's f1_score: 0.75433\n",
      "[50]\tvalid_0's multi_logloss: 0.550941\tvalid_0's f1_score: 0.78466\n",
      "[40]\tvalid_0's multi_logloss: 0.581714\tvalid_0's f1_score: 0.77312\n",
      "[60]\tvalid_0's multi_logloss: 0.55132\tvalid_0's f1_score: 0.785652\n",
      "[20]\tvalid_0's multi_logloss: 0.665618\tvalid_0's f1_score: 0.750691\n",
      "[20]\tvalid_0's multi_logloss: 0.644204\tvalid_0's f1_score: 0.751361\n",
      "[20]\tvalid_0's multi_logloss: 0.642845\tvalid_0's f1_score: 0.748721\n",
      "[70]\tvalid_0's multi_logloss: 0.533143\tvalid_0's f1_score: 0.789397\n",
      "[30]\tvalid_0's multi_logloss: 0.593207\tvalid_0's f1_score: 0.770259\n",
      "[50]\tvalid_0's multi_logloss: 0.565141\tvalid_0's f1_score: 0.781493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.565141\tvalid_0's f1_score: 0.781493\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.613441\tvalid_0's f1_score: 0.766924\n",
      "[60]\tvalid_0's multi_logloss: 0.541232\tvalid_0's f1_score: 0.787418\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[70]\tvalid_0's multi_logloss: 0.544623\tvalid_0's f1_score: 0.787894\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[30]\tvalid_0's multi_logloss: 0.597146\tvalid_0's f1_score: 0.767237\n",
      "[40]\tvalid_0's multi_logloss: 0.581552\tvalid_0's f1_score: 0.772724\n",
      "[30]\tvalid_0's multi_logloss: 0.591785\tvalid_0's f1_score: 0.768238\n",
      "[80]\tvalid_0's multi_logloss: 0.53026\tvalid_0's f1_score: 0.792916\n",
      "[40]\tvalid_0's multi_logloss: 0.565817\tvalid_0's f1_score: 0.777452\n",
      "[10]\tvalid_0's multi_logloss: 0.762413\tvalid_0's f1_score: 0.726684\n",
      "[70]\tvalid_0's multi_logloss: 0.534444\tvalid_0's f1_score: 0.789999\n",
      "[50]\tvalid_0's multi_logloss: 0.564468\tvalid_0's f1_score: 0.77772\n",
      "[80]\tvalid_0's multi_logloss: 0.542549\tvalid_0's f1_score: 0.788959\n",
      "[40]\tvalid_0's multi_logloss: 0.573399\tvalid_0's f1_score: 0.77721\n",
      "[20]\tvalid_0's multi_logloss: 0.666042\tvalid_0's f1_score: 0.744217\n",
      "[40]\tvalid_0's multi_logloss: 0.564691\tvalid_0's f1_score: 0.779273\n",
      "[90]\tvalid_0's multi_logloss: 0.529252\tvalid_0's f1_score: 0.79479\n",
      "[50]\tvalid_0's multi_logloss: 0.549624\tvalid_0's f1_score: 0.78229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.549624\tvalid_0's f1_score: 0.78229\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.551951\tvalid_0's f1_score: 0.779561\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.530133\tvalid_0's f1_score: 0.792473\n",
      "[30]\tvalid_0's multi_logloss: 0.617785\tvalid_0's f1_score: 0.756904\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[90]\tvalid_0's multi_logloss: 0.541131\tvalid_0's f1_score: 0.789465\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.544036\tvalid_0's f1_score: 0.782308\n",
      "[50]\tvalid_0's multi_logloss: 0.559275\tvalid_0's f1_score: 0.782099\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.559275\tvalid_0's f1_score: 0.782099\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.548274\tvalid_0's f1_score: 0.784459\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.547352\tvalid_0's f1_score: 0.784545\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.547352\tvalid_0's f1_score: 0.784545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.592003\tvalid_0's f1_score: 0.766836\n",
      "[100]\tvalid_0's multi_logloss: 0.529785\tvalid_0's f1_score: 0.794989\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.529252\tvalid_0's f1_score: 0.79479\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.764153\tvalid_0's f1_score: 0.721392\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[90]\tvalid_0's multi_logloss: 0.52744\tvalid_0's f1_score: 0.794692\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.540795\tvalid_0's f1_score: 0.792837\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.540198\tvalid_0's f1_score: 0.790422\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.574071\tvalid_0's f1_score: 0.775712\n",
      "[20]\tvalid_0's multi_logloss: 0.663966\tvalid_0's f1_score: 0.743662\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.529615\tvalid_0's f1_score: 0.795597\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.747045\tvalid_0's f1_score: 0.73702\n",
      "[60]\tvalid_0's multi_logloss: 0.564187\tvalid_0's f1_score: 0.779848\n",
      "[30]\tvalid_0's multi_logloss: 0.610941\tvalid_0's f1_score: 0.761766\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.741735\tvalid_0's f1_score: 0.730906\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[10]\tvalid_0's multi_logloss: 0.743107\tvalid_0's f1_score: 0.730792\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.766377\tvalid_0's f1_score: 0.724127\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[70]\tvalid_0's multi_logloss: 0.557656\tvalid_0's f1_score: 0.781734\n",
      "[40]\tvalid_0's multi_logloss: 0.581714\tvalid_0's f1_score: 0.77312\n",
      "[10]\tvalid_0's multi_logloss: 0.763945\tvalid_0's f1_score: 0.727039\n",
      "[20]\tvalid_0's multi_logloss: 0.667259\tvalid_0's f1_score: 0.747978\n",
      "[20]\tvalid_0's multi_logloss: 0.646182\tvalid_0's f1_score: 0.75433\n",
      "[10]\tvalid_0's multi_logloss: 0.76063\tvalid_0's f1_score: 0.726916\n",
      "[20]\tvalid_0's multi_logloss: 0.644204\tvalid_0's f1_score: 0.751361\n",
      "[20]\tvalid_0's multi_logloss: 0.642845\tvalid_0's f1_score: 0.748721\n",
      "[80]\tvalid_0's multi_logloss: 0.552217\tvalid_0's f1_score: 0.781808\n",
      "[50]\tvalid_0's multi_logloss: 0.565141\tvalid_0's f1_score: 0.781493\n",
      "[20]\tvalid_0's multi_logloss: 0.6694\tvalid_0's f1_score: 0.740549\n",
      "[30]\tvalid_0's multi_logloss: 0.615846\tvalid_0's f1_score: 0.764392\n",
      "[20]\tvalid_0's multi_logloss: 0.661307\tvalid_0's f1_score: 0.745517\n",
      "[90]\tvalid_0's multi_logloss: 0.547727\tvalid_0's f1_score: 0.786782\n",
      "[30]\tvalid_0's multi_logloss: 0.593207\tvalid_0's f1_score: 0.770259\n",
      "[60]\tvalid_0's multi_logloss: 0.553844\tvalid_0's f1_score: 0.784608\n",
      "[30]\tvalid_0's multi_logloss: 0.619046\tvalid_0's f1_score: 0.756549\n",
      "[40]\tvalid_0's multi_logloss: 0.585465\tvalid_0's f1_score: 0.773987\n",
      "[30]\tvalid_0's multi_logloss: 0.597146\tvalid_0's f1_score: 0.767237\n",
      "[30]\tvalid_0's multi_logloss: 0.591785\tvalid_0's f1_score: 0.768238\n",
      "[30]\tvalid_0's multi_logloss: 0.611281\tvalid_0's f1_score: 0.761158\n",
      "[100]\tvalid_0's multi_logloss: 0.545371\tvalid_0's f1_score: 0.788811\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.545329\tvalid_0's f1_score: 0.789422\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[70]\tvalid_0's multi_logloss: 0.546857\tvalid_0's f1_score: 0.7858\n",
      "[40]\tvalid_0's multi_logloss: 0.593008\tvalid_0's f1_score: 0.767201\n",
      "[50]\tvalid_0's multi_logloss: 0.567437\tvalid_0's f1_score: 0.780885\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.567437\tvalid_0's f1_score: 0.780885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.583505\tvalid_0's f1_score: 0.768992\n",
      "[40]\tvalid_0's multi_logloss: 0.565817\tvalid_0's f1_score: 0.777452\n",
      "[40]\tvalid_0's multi_logloss: 0.573399\tvalid_0's f1_score: 0.77721\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.547505\tvalid_0's f1_score: 0.786747\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.564691\tvalid_0's f1_score: 0.779273\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.577912\tvalid_0's f1_score: 0.776863\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.577912\tvalid_0's f1_score: 0.776863\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.566921\tvalid_0's f1_score: 0.774407\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.566921\tvalid_0's f1_score: 0.774407\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.549624\tvalid_0's f1_score: 0.78229\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.559275\tvalid_0's f1_score: 0.782099\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.547352\tvalid_0's f1_score: 0.784545\n",
      "[10]\tvalid_0's multi_logloss: 0.745339\tvalid_0's f1_score: 0.731362\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.74199\tvalid_0's f1_score: 0.738098\n",
      "[10]\tvalid_0's multi_logloss: 0.766377\tvalid_0's f1_score: 0.724127\n",
      "[60]\tvalid_0's multi_logloss: 0.538345\tvalid_0's f1_score: 0.791334\n",
      "[10]\tvalid_0's multi_logloss: 0.741313\tvalid_0's f1_score: 0.735027\n",
      "[10]\tvalid_0's multi_logloss: 0.763945\tvalid_0's f1_score: 0.727039\n",
      "[60]\tvalid_0's multi_logloss: 0.550699\tvalid_0's f1_score: 0.78483\n",
      "[60]\tvalid_0's multi_logloss: 0.53738\tvalid_0's f1_score: 0.78619\n",
      "[20]\tvalid_0's multi_logloss: 0.650048\tvalid_0's f1_score: 0.74719\n",
      "[20]\tvalid_0's multi_logloss: 0.667259\tvalid_0's f1_score: 0.747978\n",
      "[20]\tvalid_0's multi_logloss: 0.649856\tvalid_0's f1_score: 0.74923\n",
      "[20]\tvalid_0's multi_logloss: 0.6694\tvalid_0's f1_score: 0.740549\n",
      "[70]\tvalid_0's multi_logloss: 0.533095\tvalid_0's f1_score: 0.790853\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 0.538345\tvalid_0's f1_score: 0.791334\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.615846\tvalid_0's f1_score: 0.764392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[20]\tvalid_0's multi_logloss: 0.644502\tvalid_0's f1_score: 0.754005\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[70]\tvalid_0's multi_logloss: 0.544775\tvalid_0's f1_score: 0.785064\n",
      "[70]\tvalid_0's multi_logloss: 0.530665\tvalid_0's f1_score: 0.786085\n",
      "[30]\tvalid_0's multi_logloss: 0.619046\tvalid_0's f1_score: 0.756549\n",
      "[30]\tvalid_0's multi_logloss: 0.60174\tvalid_0's f1_score: 0.765345\n",
      "[30]\tvalid_0's multi_logloss: 0.605778\tvalid_0's f1_score: 0.766118\n",
      "[40]\tvalid_0's multi_logloss: 0.585465\tvalid_0's f1_score: 0.773987\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's multi_logloss: 0.532832\tvalid_0's f1_score: 0.788406\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.593008\tvalid_0's f1_score: 0.767201\n",
      "[30]\tvalid_0's multi_logloss: 0.596404\tvalid_0's f1_score: 0.770611\n",
      "[80]\tvalid_0's multi_logloss: 0.542046\tvalid_0's f1_score: 0.788668\n",
      "[50]\tvalid_0's multi_logloss: 0.567437\tvalid_0's f1_score: 0.780885\n",
      "[40]\tvalid_0's multi_logloss: 0.573526\tvalid_0's f1_score: 0.772957\n",
      "[10]\tvalid_0's multi_logloss: 0.76063\tvalid_0's f1_score: 0.726916\n",
      "[40]\tvalid_0's multi_logloss: 0.581243\tvalid_0's f1_score: 0.773299\n",
      "[50]\tvalid_0's multi_logloss: 0.577912\tvalid_0's f1_score: 0.776863\n",
      "[LightGBM] [Info] Total Bins 182081\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8672\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.55646\tvalid_0's f1_score: 0.780842\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.567437\tvalid_0's f1_score: 0.780885\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[40]\tvalid_0's multi_logloss: 0.570489\tvalid_0's f1_score: 0.775872\n",
      "[20]\tvalid_0's multi_logloss: 0.661307\tvalid_0's f1_score: 0.745517\n",
      "[60]\tvalid_0's multi_logloss: 0.566263\tvalid_0's f1_score: 0.779976\n",
      "[90]\tvalid_0's multi_logloss: 0.540762\tvalid_0's f1_score: 0.790953\n",
      "[50]\tvalid_0's multi_logloss: 0.557935\tvalid_0's f1_score: 0.776536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.557935\tvalid_0's f1_score: 0.776536\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[50]\tvalid_0's multi_logloss: 0.567288\tvalid_0's f1_score: 0.779739\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.567288\tvalid_0's f1_score: 0.779739\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 182862\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.745339\tvalid_0's f1_score: 0.731362\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[30]\tvalid_0's multi_logloss: 0.611281\tvalid_0's f1_score: 0.761158\n",
      "[70]\tvalid_0's multi_logloss: 0.559644\tvalid_0's f1_score: 0.78483\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.553756\tvalid_0's f1_score: 0.781579\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.553756\tvalid_0's f1_score: 0.781579\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 180662\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 8646\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.542371\tvalid_0's f1_score: 0.790711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.540672\tvalid_0's f1_score: 0.789272\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[80]\tvalid_0's multi_logloss: 0.553606\tvalid_0's f1_score: 0.784333\n",
      "[40]\tvalid_0's multi_logloss: 0.583505\tvalid_0's f1_score: 0.768992\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.766546\tvalid_0's f1_score: 0.719032\n",
      "[20]\tvalid_0's multi_logloss: 0.650048\tvalid_0's f1_score: 0.74719\n",
      "[10]\tvalid_0's multi_logloss: 0.74199\tvalid_0's f1_score: 0.738098\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.554758\tvalid_0's f1_score: 0.787081\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[50]\tvalid_0's multi_logloss: 0.566921\tvalid_0's f1_score: 0.774407\n",
      "[10]\tvalid_0's multi_logloss: 0.762573\tvalid_0's f1_score: 0.72463\n",
      "[10]\tvalid_0's multi_logloss: 0.741313\tvalid_0's f1_score: 0.735027\n",
      "[20]\tvalid_0's multi_logloss: 0.665288\tvalid_0's f1_score: 0.75106\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[10]\tvalid_0's multi_logloss: 0.764153\tvalid_0's f1_score: 0.721392\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.555352\tvalid_0's f1_score: 0.781971\n",
      "[30]\tvalid_0's multi_logloss: 0.60174\tvalid_0's f1_score: 0.765345\n",
      "[20]\tvalid_0's multi_logloss: 0.666304\tvalid_0's f1_score: 0.746276\n",
      "[20]\tvalid_0's multi_logloss: 0.649856\tvalid_0's f1_score: 0.74923\n",
      "[30]\tvalid_0's multi_logloss: 0.615462\tvalid_0's f1_score: 0.764703\n",
      "[20]\tvalid_0's multi_logloss: 0.663268\tvalid_0's f1_score: 0.746488\n",
      "[20]\tvalid_0's multi_logloss: 0.644502\tvalid_0's f1_score: 0.754005\n",
      "[70]\tvalid_0's multi_logloss: 0.546457\tvalid_0's f1_score: 0.788462\n",
      "[10]\tvalid_0's multi_logloss: 0.747772\tvalid_0's f1_score: 0.735406\n",
      "[30]\tvalid_0's multi_logloss: 0.617227\tvalid_0's f1_score: 0.762536\n",
      "[40]\tvalid_0's multi_logloss: 0.587096\tvalid_0's f1_score: 0.7722\n",
      "[30]\tvalid_0's multi_logloss: 0.612778\tvalid_0's f1_score: 0.762388\n",
      "[40]\tvalid_0's multi_logloss: 0.573526\tvalid_0's f1_score: 0.772957\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's multi_logloss: 0.548198\tvalid_0's f1_score: 0.789139\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.605778\tvalid_0's f1_score: 0.766118\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[40]\tvalid_0's multi_logloss: 0.591126\tvalid_0's f1_score: 0.76894\n",
      "[50]\tvalid_0's multi_logloss: 0.569762\tvalid_0's f1_score: 0.778114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.569762\tvalid_0's f1_score: 0.778114\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.596404\tvalid_0's f1_score: 0.770611\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[40]\tvalid_0's multi_logloss: 0.584127\tvalid_0's f1_score: 0.769842\n",
      "[20]\tvalid_0's multi_logloss: 0.652116\tvalid_0's f1_score: 0.745904\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\tvalid_0's multi_logloss: 0.575744\tvalid_0's f1_score: 0.775719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.575744\tvalid_0's f1_score: 0.775719\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.557935\tvalid_0's f1_score: 0.776536\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.581243\tvalid_0's f1_score: 0.773299\n",
      "[50]\tvalid_0's multi_logloss: 0.566103\tvalid_0's f1_score: 0.779599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.566103\tvalid_0's f1_score: 0.779599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.570489\tvalid_0's f1_score: 0.775872\n",
      "[10]\tvalid_0's multi_logloss: 0.741875\tvalid_0's f1_score: 0.733858\n",
      "[30]\tvalid_0's multi_logloss: 0.60314\tvalid_0's f1_score: 0.762026\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[60]\tvalid_0's multi_logloss: 0.549468\tvalid_0's f1_score: 0.778361\n",
      "[10]\tvalid_0's multi_logloss: 0.743394\tvalid_0's f1_score: 0.734034\n",
      "[50]\tvalid_0's multi_logloss: 0.567288\tvalid_0's f1_score: 0.779739\n",
      "[10]\tvalid_0's multi_logloss: 0.766546\tvalid_0's f1_score: 0.719032\n",
      "[10]\tvalid_0's multi_logloss: 0.762573\tvalid_0's f1_score: 0.72463\n",
      "[50]\tvalid_0's multi_logloss: 0.553756\tvalid_0's f1_score: 0.781579\n",
      "[20]\tvalid_0's multi_logloss: 0.647675\tvalid_0's f1_score: 0.750324\n",
      "[40]\tvalid_0's multi_logloss: 0.576369\tvalid_0's f1_score: 0.775821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's multi_logloss: 0.665288\tvalid_0's f1_score: 0.75106\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.544241\tvalid_0's f1_score: 0.782284\n",
      "[20]\tvalid_0's multi_logloss: 0.645057\tvalid_0's f1_score: 0.751774\n",
      "[60]\tvalid_0's multi_logloss: 0.559527\tvalid_0's f1_score: 0.782917\n",
      "[20]\tvalid_0's multi_logloss: 0.666304\tvalid_0's f1_score: 0.746276\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.615462\tvalid_0's f1_score: 0.764703\n",
      "[60]\tvalid_0's multi_logloss: 0.543883\tvalid_0's f1_score: 0.789292\n",
      "[50]\tvalid_0's multi_logloss: 0.560581\tvalid_0's f1_score: 0.781338\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.560581\tvalid_0's f1_score: 0.781338\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[30]\tvalid_0's multi_logloss: 0.602526\tvalid_0's f1_score: 0.764953\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.617227\tvalid_0's f1_score: 0.762536\n",
      "[80]\tvalid_0's multi_logloss: 0.54056\tvalid_0's f1_score: 0.783799\n",
      "[70]\tvalid_0's multi_logloss: 0.553102\tvalid_0's f1_score: 0.786778\n",
      "[40]\tvalid_0's multi_logloss: 0.587096\tvalid_0's f1_score: 0.7722\n",
      "[30]\tvalid_0's multi_logloss: 0.597917\tvalid_0's f1_score: 0.769003\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[40]\tvalid_0's multi_logloss: 0.591126\tvalid_0's f1_score: 0.76894\n",
      "[70]\tvalid_0's multi_logloss: 0.538125\tvalid_0's f1_score: 0.790547\n",
      "[40]\tvalid_0's multi_logloss: 0.578403\tvalid_0's f1_score: 0.770551\n",
      "[50]\tvalid_0's multi_logloss: 0.569762\tvalid_0's f1_score: 0.778114\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's multi_logloss: 0.764153\tvalid_0's f1_score: 0.721392\n",
      "[90]\tvalid_0's multi_logloss: 0.537457\tvalid_0's f1_score: 0.786003\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.549223\tvalid_0's f1_score: 0.787528\n",
      "[50]\tvalid_0's multi_logloss: 0.575744\tvalid_0's f1_score: 0.775719\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.573386\tvalid_0's f1_score: 0.771501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.558245\tvalid_0's f1_score: 0.780889\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.538724\tvalid_0's f1_score: 0.791042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's multi_logloss: 0.567328\tvalid_0's f1_score: 0.781361\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[20]\tvalid_0's multi_logloss: 0.663268\tvalid_0's f1_score: 0.746488\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.565505\tvalid_0's f1_score: 0.780689\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.565505\tvalid_0's f1_score: 0.780689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.567566\tvalid_0's f1_score: 0.77607\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[100]\tvalid_0's multi_logloss: 0.534744\tvalid_0's f1_score: 0.787596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.534744\tvalid_0's f1_score: 0.787596\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 160107\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5042\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 0.571715\tvalid_0's f1_score: 0.779477\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[90]\tvalid_0's multi_logloss: 0.545848\tvalid_0's f1_score: 0.788415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Info] Total Bins 160767\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5070\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[50]\tvalid_0's multi_logloss: 0.560317\tvalid_0's f1_score: 0.778607\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.560317\tvalid_0's f1_score: 0.778607\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's multi_logloss: 0.612778\tvalid_0's f1_score: 0.762388\n",
      "[LightGBM] [Info] Total Bins 158655\n",
      "[LightGBM] [Info] Number of data points in the train set: 13258, number of used features: 5003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's multi_logloss: 0.584127\tvalid_0's f1_score: 0.769842\n",
      "[100]\tvalid_0's multi_logloss: 0.543166\tvalid_0's f1_score: 0.788478\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.543166\tvalid_0's f1_score: 0.788478\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[10]\tvalid_0's multi_logloss: 0.747772\tvalid_0's f1_score: 0.735406\n",
      "[10]\tvalid_0's multi_logloss: 0.741875\tvalid_0's f1_score: 0.733858\n",
      "[10]\tvalid_0's multi_logloss: 0.743394\tvalid_0's f1_score: 0.734034\n",
      "[50]\tvalid_0's multi_logloss: 0.566103\tvalid_0's f1_score: 0.779599\n",
      "[20]\tvalid_0's multi_logloss: 0.652116\tvalid_0's f1_score: 0.745904\n",
      "[60]\tvalid_0's multi_logloss: 0.55617\tvalid_0's f1_score: 0.780269\n",
      "[20]\tvalid_0's multi_logloss: 0.647675\tvalid_0's f1_score: 0.750324\n",
      "[20]\tvalid_0's multi_logloss: 0.645057\tvalid_0's f1_score: 0.751774\n",
      "[70]\tvalid_0's multi_logloss: 0.547095\tvalid_0's f1_score: 0.785063\n",
      "[30]\tvalid_0's multi_logloss: 0.60314\tvalid_0's f1_score: 0.762026\n",
      "[30]\tvalid_0's multi_logloss: 0.602526\tvalid_0's f1_score: 0.764953\n",
      "[30]\tvalid_0's multi_logloss: 0.597917\tvalid_0's f1_score: 0.769003\n",
      "[80]\tvalid_0's multi_logloss: 0.540394\tvalid_0's f1_score: 0.789244\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.534896\tvalid_0's f1_score: 0.789854\n",
      "[40]\tvalid_0's multi_logloss: 0.576369\tvalid_0's f1_score: 0.775821\n",
      "[40]\tvalid_0's multi_logloss: 0.578403\tvalid_0's f1_score: 0.770551\n",
      "[40]\tvalid_0's multi_logloss: 0.573386\tvalid_0's f1_score: 0.771501\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.530929\tvalid_0's f1_score: 0.79175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.530929\tvalid_0's f1_score: 0.79175\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.560581\tvalid_0's f1_score: 0.781338\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.565505\tvalid_0's f1_score: 0.780689\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's multi_logloss: 0.560317\tvalid_0's f1_score: 0.778607\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.55102\tvalid_0's f1_score: 0.780259\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[60]\tvalid_0's multi_logloss: 0.557798\tvalid_0's f1_score: 0.779672\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.565505\tvalid_0's f1_score: 0.780689\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[60]\tvalid_0's multi_logloss: 0.550609\tvalid_0's f1_score: 0.783385\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.54448\tvalid_0's f1_score: 0.783066\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.542941\tvalid_0's f1_score: 0.787258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.539839\tvalid_0's f1_score: 0.783255\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.537906\tvalid_0's f1_score: 0.788536\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's multi_logloss: 0.542085\tvalid_0's f1_score: 0.784206\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.534163\tvalid_0's f1_score: 0.793308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.531125\tvalid_0's f1_score: 0.792156\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.531125\tvalid_0's f1_score: 0.792156\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Total Bins 255032\n",
      "[LightGBM] [Info] Number of data points in the train set: 19887, number of used features: 9701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\tvalid_0's multi_logloss: 0.74115\tvalid_0's f1_score: 0.735774\n",
      "[20]\tvalid_0's multi_logloss: 0.641353\tvalid_0's f1_score: 0.753547\n",
      "[30]\tvalid_0's multi_logloss: 0.590429\tvalid_0's f1_score: 0.766635\n",
      "[40]\tvalid_0's multi_logloss: 0.561373\tvalid_0's f1_score: 0.778491\n",
      "[50]\tvalid_0's multi_logloss: 0.543652\tvalid_0's f1_score: 0.786979\n",
      "[60]\tvalid_0's multi_logloss: 0.532297\tvalid_0's f1_score: 0.792101\n",
      "[70]\tvalid_0's multi_logloss: 0.525597\tvalid_0's f1_score: 0.797461\n",
      "[80]\tvalid_0's multi_logloss: 0.519901\tvalid_0's f1_score: 0.796882\n",
      "[90]\tvalid_0's multi_logloss: 0.516874\tvalid_0's f1_score: 0.799002\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.51757\tvalid_0's f1_score: 0.800738\n",
      "Best Parameters for LightGBM: {'learning_rate': 0.1, 'max_depth': -1, 'min_data_in_leaf': 10, 'n_estimators': 100, 'num_leaves': 50}\n",
      "Best Cross-Validation Accuracy: 0.8440\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid\n",
    "param_grid_lgbm = {\n",
    "    \"learning_rate\": [0.01, 0.1],  # Controls the contribution of each tree during boosting\n",
    "    \"n_estimators\": [50, 100],     # Number of boosting stages (trees) to train\n",
    "    \"max_depth\": [-1, 20],         # Maximum depth of the trees (-1 means no limit)\n",
    "    \"num_leaves\": [31, 50],        # Maximum number of leaves per tree (controls tree complexity)\n",
    "    \"min_data_in_leaf\": [10, 20]   # Controls leaf size for better generalization\n",
    "}\n",
    "\n",
    "# Initialize LightGBM model with balanced class weights\n",
    "lgbm_model = LGBMClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    force_col_wise=True,  # Optimizes memory usage\n",
    "    min_split_gain=0.001, # Minimum gain to split a node\n",
    ")\n",
    "\n",
    "# Define callbacks to enhance training\n",
    "callbacks = [\n",
    "    early_stopping(stopping_rounds=10),  # Stops training if no improvement for 10 rounds\n",
    "    log_evaluation(period=10)            # Logs training progress every 10 iterations\n",
    "]\n",
    "\n",
    "# Initialize GridSearchCV for hyperparameter tuning\n",
    "grid_search_lgbm = GridSearchCV(\n",
    "    estimator=lgbm_model,\n",
    "    param_grid=param_grid_lgbm,\n",
    "    cv=cross_validation,         \n",
    "    scoring=f1_weighted_scorer,         # Weighted F1-score as the evaluation metric for hyperparameter search\n",
    "    verbose=True,\n",
    "    n_jobs=-1                                    \n",
    ")\n",
    "\n",
    "# Fit the GribSearchCV on training data\n",
    "grid_search_lgbm.fit(\n",
    "    X_train_resampled, \n",
    "    y_train_resampled, \n",
    "    eval_set=[(X_test, y_test)],                 # Validation set for monitoring during training\n",
    "    eval_metric=custom_f1_metric_lightgbm,       # Custom F1-score metric for validation\n",
    "    callbacks= callbacks)                        # Callbacks for early stopping and logging\n",
    "\n",
    "\n",
    "# Extract the best parameters and cross-validation accuracy\n",
    "best_params_lgbm = grid_search_lgbm.best_params_\n",
    "print(f\"Best Parameters for LightGBM: {best_params_lgbm}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search_lgbm.best_score_:.4f}\")\n",
    "\n",
    "# Extract the best model with best parameters \n",
    "best_model_lgbm = grid_search_lgbm.best_estimator_\n",
    "\n",
    "# Evaluate best model on the test set\n",
    "y_pred = best_model_lgbm.predict(X_test)\n",
    "\n",
    "# Save the trained model to a file for later use\n",
    "joblib.dump(best_model_lgbm, '../models/lightgbm_enhanced_model.pkl')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cae4fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>502</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>93</td>\n",
       "      <td>568</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>71</td>\n",
       "      <td>170</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              502       86        89\n",
       "Neutral                93      568       123\n",
       "Positive               71      170      1457"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confusion matrix for model prediction using panda crosstab\n",
    "cm_enhanced_lgbm= pd.crosstab(y_test, y_pred, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "cm_enhanced_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fb52a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification report with evaluation metrics\n",
    "report_enhanced_lgbm = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract weighted avg metrics\n",
    "weighted_avg_enhanced_lgbm = report_enhanced_lgbm[\"weighted avg\"]\n",
    "\n",
    "# Access evaluation metrics\n",
    "accuracy_enhanced_lgbm = round(accuracy_score(y_true=y_test, y_pred=y_pred), 2)\n",
    "recall_enhanced_lgbm = round(weighted_avg_enhanced_lgbm[\"recall\"], 2)\n",
    "precision_enhanced_lgbm = round(weighted_avg_enhanced_lgbm[\"precision\"], 2)\n",
    "f1_score_enhanced_lgbm = round(weighted_avg_enhanced_lgbm[\"f1-score\"], 2)\n",
    "f3_score_enhanced_lgbm = round(fbeta_score(y_true=y_test, y_pred=y_pred, average=\"weighted\", beta=3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "06f72124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.80\n",
      "Classification Report:\n",
      "\n",
      "Before tuning:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.74      0.74       677\n",
      "     Neutral       0.68      0.71      0.70       784\n",
      "    Positive       0.87      0.85      0.86      1698\n",
      "\n",
      "    accuracy                           0.79      3159\n",
      "   macro avg       0.76      0.77      0.77      3159\n",
      "weighted avg       0.80      0.79      0.79      3159\n",
      "\n",
      "\n",
      "After tuning:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.74      0.75       677\n",
      "     Neutral       0.69      0.72      0.71       784\n",
      "    Positive       0.87      0.86      0.87      1698\n",
      "\n",
      "    accuracy                           0.80      3159\n",
      "   macro avg       0.77      0.77      0.77      3159\n",
      "weighted avg       0.80      0.80      0.80      3159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "classification_report_enhanced_lgbm = classification_report(y_test, y_pred)\n",
    "print(\"\\nBefore tuning:\")\n",
    "print(\"-\" * 50)\n",
    "print(classification_report_lgbm)\n",
    "print(\"\\nAfter tuning:\")\n",
    "print(\"-\" * 50)\n",
    "print(classification_report_enhanced_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64861f86",
   "metadata": {},
   "source": [
    "The LightGBM model after tuning shows a slight but meaningful improvement in accuracy, precision, and F1-scores. \n",
    "\n",
    "**Key Improvements:**\n",
    "\n",
    "- Neutral Class Performance: Tuning had the most significant impact on the neutral class, reducing its overlap with the negative and positive classes.\n",
    "- Negative Class Precision: Better separation from the neutral class resulted in fewer false positives.\n",
    "- Overall Consistency: All metrics for the positive class remained strong, indicating that tuning maintained the model’s ability to classify the dominant class effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803edf33",
   "metadata": {},
   "source": [
    "# VII. Final Model Validation on New Reviews\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                           Review\n",
      "0                                                                                                        This product is perfect!\n",
      "1                                                                                I don't recommend this product, it doesn't work.\n",
      "2                                                                                            The laptop is okay, nothing special.\n",
      "3  I love my blink cameras and it’s handy having our subscription plan setup through Amazon to make it easy to purchase the plan!\n",
      "4                                                                                           Terrible experience with this device.\n",
      "5                                                                          The product is ok. Camera can be better. Little heavy.\n",
      "6                                            I love it! Best purchase ever. I like it because I can see all around my front yard.\n",
      "7                         Product is ok ok only. Main cons is volume is low for calls . Especially in MI phones. So consider this\n",
      "8                                    Breakdown after 3 weeks. Don't buy, really lousy customer service, no refund or gift code!!!\n",
      "9                                    Pc that supports games like League Of Legends with the RTX 3080 ti GE and the ryzen 9 3900X.\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with 10 new reviews\n",
    "df_new_data = pd.DataFrame({\n",
    "        \"Review\": [\n",
    "            \"This product is perfect!\",\n",
    "            \"I don't recommend this product, it doesn't work.\",\n",
    "            \"The laptop is okay, nothing special.\",\n",
    "            \"I love my blink cameras and it’s handy having our subscription plan setup through Amazon to make it easy to purchase the plan!\",\n",
    "            \"Terrible experience with this device.\",\n",
    "            \"The product is ok. Camera can be better. Little heavy.\",\n",
    "            \"I love it! Best purchase ever. I like it because I can see all around my front yard.\",\n",
    "            \"Product is ok ok only. Main cons is volume is low for calls . Especially in MI phones. So consider this\",\n",
    "            \"Breakdown after 3 weeks. Don't buy, really lousy customer service, no refund or gift code!!!\",\n",
    "            \"Pc that supports games like League Of Legends with the RTX 3080 ti GE and the ryzen 9 3900X.\",\n",
    "        ]\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce96b0b",
   "metadata": {},
   "source": [
    "## <font color=\"red\">1.  Preprocessing the New Reviews</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4d6ce403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to convert NLTK POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if POS tag is unknown\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_reviews(dataframe, column_name='Review'):\n",
    "    \"\"\"\n",
    "    Preprocess reviews in a DataFrame column for text analysis.\n",
    "    \n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the text data.\n",
    "        column_name (str): The column name with text data to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the preprocessed text.\n",
    "    \"\"\"\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    # Convert to lowercase\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "\n",
    "    # Decode HTML entities\n",
    "    df[column_name] = df[column_name].apply(html.unescape)\n",
    "\n",
    "    # Expand contractions\n",
    "    df[column_name] = df[column_name].apply(contractions.fix)\n",
    "\n",
    "    # Tokenize, remove punctuation, and lemmatize with POS tagging\n",
    "    def tokenize_and_lemmatize(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in pos_tags]\n",
    "        return \" \".join(lemmatized_tokens)\n",
    "    \n",
    "    df[column_name] = df[column_name].apply(tokenize_and_lemmatize)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    df[column_name] = df[column_name].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "    # Remove all punctuation, including apostrophes\n",
    "    df[column_name] = df[column_name].str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "\n",
    "    # Remove numeric characters\n",
    "    df[column_name] = df[column_name].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "    # Load general English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Define words to keep for sentiment analysis\n",
    "    important_words = {\n",
    "        \"doesn\", \"doesn't\", \"doesnt\", \"dont\", \"don't\", \"not\", \"wasn't\", \"wasnt\",\n",
    "        \"aren\", \"aren't\", \"arent\",  \"couldn\", \"couldn't\", \"couldnt\", \"didn\",\n",
    "        \"didn't\", \"didnt\", \"hadn\", \"hadn't\", \"hadnt\",  \"hasn\", \"hasn't\", \"hasnt\",\n",
    "        \"haven't\", \"havent\", \"isn\", \"isn't\", \"isnt\", \"mightn\",  \"mightn't\",\n",
    "        \"mightnt\", \"mustn\", \"mustn't\", \"mustnt\", \"needn\", \"needn't\", \"neednt\",\n",
    "        \"shan\", \"shan't\", \"shant\", \"shouldn\", \"shouldn't\", \"shouldnt\", \"wasn\",\n",
    "        \"wasn't\",  \"wasnt\", \"weren\", \"weren't\", \"werent\", \"won\", \"won't\", \"wont\",\n",
    "        \"wouldn\", \"wouldn't\", \"wouldnt\", \"good\", \"bad\", \"worst\", \"wonderfull\",\n",
    "        \"best\", \"better\", \"not\", \"no\", \"but\", \"yet\", \"never\", \"none\"\n",
    "    }\n",
    "\n",
    "    # Remove important words from stop words list\n",
    "    custom_stop_words = stop_words - important_words\n",
    "\n",
    "    # Remove customized stop words\n",
    "    df[column_name] = df[column_name].apply(\n",
    "        lambda x: ' '.join([word for word in x.split() if word not in custom_stop_words])\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6fca58ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not recommend product not work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laptop okay nothing special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>love blink camera handy subscription plan setup amazon make easy purchase plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrible experience device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>product ok camera good little heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>love best purchase ever like see around front yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>product ok ok main con volume low call especially mi phone consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breakdown week not buy really lousy customer service no refund gift code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pc support game like league legend rtx ti ge ryzen x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           Review\n",
       "0                                                                 product perfect\n",
       "1                                                  not recommend product not work\n",
       "2                                                     laptop okay nothing special\n",
       "3  love blink camera handy subscription plan setup amazon make easy purchase plan\n",
       "4                                                      terrible experience device\n",
       "5                                             product ok camera good little heavy\n",
       "6                              love best purchase ever like see around front yard\n",
       "7             product ok ok main con volume low call especially mi phone consider\n",
       "8        breakdown week not buy really lousy customer service no refund gift code\n",
       "9                            pc support game like league legend rtx ti ge ryzen x"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_data_ml = df_new_data.copy()\n",
    "\n",
    "# Preprocess the reviews\n",
    "df_new_data_ml = preprocess_reviews(df_new_data, column_name='Review')\n",
    "\n",
    "# Display the preprocessed DataFrame\n",
    "df_new_data_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9e695018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the new reviews using the fitted TfidfVectorizer\n",
    "vectorizer = joblib.load('../models/tfidf_vectorizer_enhanced.joblib') # Load the trained vectorizer from the file\n",
    "\n",
    "X_new_data_tfidf = vectorizer.transform(df_new_data_ml[\"Review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e8866",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.  Performing Predictions on New Reviews</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8a9b6317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Negative proba</th>\n",
       "      <th>Neutral proba</th>\n",
       "      <th>Positive proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product is perfect!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.8580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't recommend this product, it doesn't work.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.6954</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The laptop is okay, nothing special.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love my blink cameras and it’s handy having our subscription plan setup through Amazon to make it easy to purchase the plan!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.9906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience with this device.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.8524</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.0419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The product is ok. Camera can be better. Little heavy.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love it! Best purchase ever. I like it because I can see all around my front yard.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.9791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Product is ok ok only. Main cons is volume is low for calls . Especially in MI phones. So consider this</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Breakdown after 3 weeks. Don't buy, really lousy customer service, no refund or gift code!!!</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pc that supports games like League Of Legends with the RTX 3080 ti GE and the ryzen 9 3900X.</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>0.4919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                           Review  \\\n",
       "0                                                                                                        This product is perfect!   \n",
       "1                                                                                I don't recommend this product, it doesn't work.   \n",
       "2                                                                                            The laptop is okay, nothing special.   \n",
       "3  I love my blink cameras and it’s handy having our subscription plan setup through Amazon to make it easy to purchase the plan!   \n",
       "4                                                                                           Terrible experience with this device.   \n",
       "5                                                                          The product is ok. Camera can be better. Little heavy.   \n",
       "6                                            I love it! Best purchase ever. I like it because I can see all around my front yard.   \n",
       "7                         Product is ok ok only. Main cons is volume is low for calls . Especially in MI phones. So consider this   \n",
       "8                                    Breakdown after 3 weeks. Don't buy, really lousy customer service, no refund or gift code!!!   \n",
       "9                                    Pc that supports games like League Of Legends with the RTX 3080 ti GE and the ryzen 9 3900X.   \n",
       "\n",
       "  Prediction  Negative proba  Neutral proba  Positive proba  \n",
       "0   Positive          0.0750         0.0670          0.8580  \n",
       "1   Negative          0.6954         0.2637          0.0410  \n",
       "2    Neutral          0.0878         0.8020          0.1102  \n",
       "3   Positive          0.0018         0.0076          0.9906  \n",
       "4   Negative          0.8524         0.1057          0.0419  \n",
       "5    Neutral          0.0646         0.8570          0.0784  \n",
       "6   Positive          0.0084         0.0125          0.9791  \n",
       "7   Negative          0.6469         0.1717          0.1814  \n",
       "8   Negative          0.9044         0.0272          0.0684  \n",
       "9   Positive          0.1248         0.3833          0.4919  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "final_model = joblib.load('../models/lightgbm_enhanced_model.pkl')\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred_final = final_model.predict(X_new_data_tfidf)\n",
    "\n",
    "y_pred_proba = final_model.predict_proba(X_new_data_tfidf)\n",
    "y_pred_proba = np.round(y_pred_proba, decimals=4)\n",
    "\n",
    "# Create the predictions DataFrame\n",
    "predictions_enhanced = df_new_data[[\"Review\"]].copy()\n",
    "predictions_enhanced[\"Prediction\"] = y_pred_final\n",
    "predictions_enhanced[\"Negative proba\"] = y_pred_proba[:, 0]\n",
    "predictions_enhanced[\"Neutral proba\"] = y_pred_proba[:, 1]\n",
    "predictions_enhanced[\"Positive proba\"] = y_pred_proba[:, 2]\n",
    "\n",
    "# Temporarily change display options to show full text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "predictions_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a2fe1",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>Performance Overview:</u></font>\n",
    "\n",
    "- Correctly Classified: 9 reviews.\n",
    "- Misclassified: 1 review (Review #7 should be neutral but was predicted as negative).\n",
    "- Accuracy: 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368de996",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>Class-Level Performance:</u></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eb921a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Final Model Prediction on 10 new reivews :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative                3        0         0\n",
       "Neutral                 1        2         0\n",
       "Positive                0        0         4"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_final = ['Positive', 'Negative', 'Neutral', 'Positive', 'Negative', 'Neutral', 'Positive', 'Neutral', 'Negative', 'Positive']\n",
    "\n",
    "# Generate confusion matrix for model prediction on 20 new reviews\n",
    "cm_lstm_final = pd.crosstab(y_test_final, y_pred_final, rownames=[\"Real class\"], colnames=[\"Predicted class\"])\n",
    "print(\"Confusion Matrix for Final Model Prediction on 10 new reivews :\")\n",
    "cm_lstm_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780958f0",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>Strengths:</u></font>\n",
    "\n",
    "- Performs well for clearly polarized sentiments, particularly for positive and negative classes.\n",
    "- Demonstrates strong confidence and class separation for most reviews.\n",
    "\n",
    "<font color=\"yellow\"><u>Weaknesses:</u></font>\n",
    "\n",
    "- Struggles with ambiguous or mixed sentiments, as shown by the misclassification of Review #7.\n",
    "- Slight overlap between neutral and negative classes\n",
    "\n",
    "<font color=\"yellow\"><u>Challenges:</u></font>\n",
    "\n",
    "- Neutral reviews remain the most challenging to classify, especially when sentiment overlaps with negative traits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde29dce",
   "metadata": {},
   "source": [
    "<font color=\"yellow\"><u>CONCLUSION</u></font>\n",
    "\n",
    "- The model achieves a solid 90% accuracy for this small validation set, effectively classifying most reviews.\n",
    "- While positive and negative reviews are handled well, improving neutral class predictions and reducing overlap with other classes should be a focus for further fine-tuning. This will help address subtle sentiment differences and improve overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af24a2e",
   "metadata": {},
   "source": [
    "# VIII. Data visualization on Final Model Performance\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31a9e95",
   "metadata": {},
   "source": [
    "## <font color=\"red\">1.  Confusion Matrix Heatmap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c36ac6",
   "metadata": {},
   "source": [
    "The confusion matrix provides valuable insights into the performance of the LightGBM model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "39a4e4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted class</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>502</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>93</td>\n",
       "      <td>568</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>71</td>\n",
       "      <td>170</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted class  Negative  Neutral  Positive\n",
       "Real class                                  \n",
       "Negative              502       86        89\n",
       "Neutral                93      568       123\n",
       "Positive               71      170      1457"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_enhanced_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c86acba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classes = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_enhanced_lgbm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf0ac2",
   "metadata": {},
   "source": [
    "**Performance Insights:**\n",
    "- The model performs well for the positive class, with the highest number of correct predictions (1448) and fewer misclassifications compared to other classes.\n",
    "- Neutral class shows a moderate number of misclassifications, with a higher tendency to be confused with the positive class.\n",
    "- Negative class has relatively fewer misclassifications but is more often confused with the neutral class than the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac629e0f",
   "metadata": {},
   "source": [
    "## <font color=\"red\">2.  Classification Report Metrics Column Chart</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5f1816d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classes = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "\n",
    "# Generate classification report\n",
    "target_names = classes\n",
    "\n",
    "# Convert classification report to DataFrame\n",
    "df_metrics = pd.DataFrame(report_enhanced_lgbm).transpose()\n",
    "df_metrics = df_metrics.loc[classes, [\"precision\", \"recall\", \"f1-score\"]]\n",
    "\n",
    "# Plot classification report metrics\n",
    "ax = df_metrics.plot(kind=\"bar\", figsize=(8, 6), color=[\"skyblue\", \"lightgreen\", \"salmon\"])\n",
    "plt.title(\"Classification Report Metrics\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Metric\")\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114b624",
   "metadata": {},
   "source": [
    "**Overall Trends:**\n",
    "- The positive class has the strongest performance, which is expected given the dataset's likely class imbalance.\n",
    "- The neutral class is the most challenging for the model, as it shows the lowest precision, indicating confusion with neighboring sentiments (negative and positive).\n",
    "- The negative class performs moderately well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
